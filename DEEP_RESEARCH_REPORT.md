# üî¨ ExplainMyXray v2‚Üív3 Deep Research Report

> **Generated:** February 10, 2026 | **Model:** Claude Opus 4.6 | **Scope:** Medical VLM Research  
> **Attachments studied:** `architecture_prompt.json` (875 lines), `CLAUDE_PROMPT.md`, `README.md`  
> **Constraint:** All recommendations must work on RTX 4080 Laptop (12 GB VRAM)

---

## Part A: Research

---

### A1. Recent News & Developments

#### A1.1 Model Releases & Updates (Jan 2025 ‚Äì Feb 2026)

| # | Model / Announcement | Organization | Date | Key Innovation | Relevance to ExplainMyXray | Source URL |
|---|---------------------|-------------|------|----------------|---------------------------|-----------|
| 1 | **MedGemma 1.5 4B-it** ‚≠ê | Google | Jan 13, 2026 | Native bounding-box localization (Chest ImaGenome IoU 3.1‚Üí38.0), longitudinal CXR comparison, 3D CT/MRI support, WSI histopathology | ‚¨ÜÔ∏è High ‚Äî drop-in replacement, native bbox eliminates our manual 26-region mapping | https://huggingface.co/google/medgemma-1.5-4b-it |
| 2 | MedGemma 1.5 greedy decoding update | Google | Jan 23, 2026 | Default generation config changed to greedy decoding (do_sample=False) for more deterministic outputs | ‚¨ÜÔ∏è High ‚Äî affects inference reproducibility, may improve structured report consistency | https://huggingface.co/google/medgemma-1.5-4b-it |
| 3 | MedGemma 1.0.1 4B-it (bug fix) | Google | Jul 9, 2025 | Patch release fixing v1.0.0 issues; MIMIC-CXR macro F1=88.9 (top 5 conditions) | ‚û°Ô∏è Medium ‚Äî our current model, superseded by v1.5 | https://huggingface.co/google/medgemma-4b-it |
| 4 | CheXagent-2-3b | Stanford AIMI | Apr 29, 2024 (updated Jan 2026) | CXR-specific VLM built on Phi architecture, 3B params, MIT license, structured report generation | ‚¨ÜÔ∏è High ‚Äî ensemble candidate for CXR-specific tasks, fits 12 GB easily | https://huggingface.co/StanfordAIMI/CheXagent-2-3b |
| 5 | CheXagent-2-3b-srrg-findings | Stanford AIMI | Jan 2026 | Fine-tuned variant specifically for structured radiology report generation (findings extraction) | ‚¨ÜÔ∏è High ‚Äî directly comparable to our FINDINGS output format | https://huggingface.co/StanfordAIMI/CheXagent-2-3b-srrg-findings |
| 6 | MedSAM-Agent-Qwen3-VL-8B | Saint-lsy | Feb 2026 | 9B agent combining Qwen3-VL with MedSAM2 for interactive medical image segmentation | ‚û°Ô∏è Medium ‚Äî too large for 12 GB training, but demonstrates MedSAM + VLM integration pattern | https://huggingface.co/Saint-lsy/MedSAM-Agent-Qwen3-VL-8B |
| 7 | Transformers v5.0.0 (major release) | Hugging Face | Jan 27, 2026 | First major version in 5 years: dynamic weight loading, tokenizer backend refactoring, default dtype "auto", min PyTorch 2.4, weekly minor releases | ‚¨ÜÔ∏è High ‚Äî breaking changes require pipeline migration | https://github.com/huggingface/transformers/releases |
| 8 | Phi-4-multimodal-instruct | Microsoft | Jan 2025 | 5.6B multimodal model with vision, speech, text. No medical pretraining but efficient architecture | ‚¨áÔ∏è Low ‚Äî no medical pretraining, 5.6B tight for 12 GB QLoRA training | https://huggingface.co/microsoft/Phi-4-multimodal-instruct |
| 9 | Gemma 3 4B-it | Google | 2025 | Base model underlying MedGemma; 128K context, GQA, BF16 tensor cores | ‚û°Ô∏è Medium ‚Äî foundational, already used via MedGemma | https://huggingface.co/google/gemma-3-4b-it |
| 10 | PaliGemma 2 3B | Google | Late 2024 | Updated PaliGemma with SigLIP 896¬≤ vision encoder, improved transfer learning | ‚¨áÔ∏è Low ‚Äî no medical pretraining, our v1 used PaliGemma and we moved away | https://huggingface.co/google/paligemma2-3b-pt-896 |
| 11 | Qwen2.5-VL-7B-Instruct | Alibaba Qwen | Late 2024 | General VLM with strong visual reasoning, dynamic resolution, 7B params | ‚¨áÔ∏è Low ‚Äî 7B tight for 12 GB, no medical pretraining | https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct |
| 12 | InternVL2-8B | OpenGVLab / Shanghai AI Lab | 2024 | Strong open-source VLM, 8B params, competitive with GPT-4V on many benchmarks | ‚¨áÔ∏è Low ‚Äî 8B won't fit 12 GB for QLoRA training | https://huggingface.co/OpenGVLab/InternVL2-8B |
| 13 | Google Health AI Developer Foundations | Google | 2025 | Umbrella program for MedGemma, MedSigLIP, BiomedCLIP-style models; HAI-DEF collection on HuggingFace (22 items) | ‚¨ÜÔ∏è High ‚Äî ecosystem around MedGemma, includes tutorial notebooks and fine-tuning guides | https://huggingface.co/collections/google/health-ai-developer-foundations-hai-def |
| 14 | BiomedCLIP-PubMedBERT_256 | Microsoft | Updated Jan 2025 | Medical CLIP model: PubMedBERT text encoder + ViT vision encoder, trained on PMC-15M figure-caption pairs. 497K downloads | ‚û°Ô∏è Medium ‚Äî excellent for CXR embedding/retrieval, image quality scoring | https://huggingface.co/microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224 |

---

#### A1.2 Framework & Library Updates

| # | Library | Update | Version | What Changed | Impact on Our Pipeline | Migration Effort |
|---|---------|--------|---------|-------------|----------------------|-----------------|
| 1 | **Transformers** | Major v5 release ‚≠ê | ‚â•5.1.0 | Dynamic weight loading, tokenizer backend refactoring, default dtype "auto", min PyTorch 2.4. v5.1.0 adds EXAONE-MoE, PP-DocLayoutV3 | üî¥ Breaking ‚Äî must update imports, check dtype handling, verify PyTorch version | Medium |
| 2 | **TRL** | forward_masked_logits ‚≠ê | ‚â•0.27.2 | v0.27.0: `forward_masked_logits` reduces VRAM by up to 50% during forward pass. GDPO, CISPO loss functions, agent training, vLLM 0.12 support. v0.27.2: Transformers v5 compatibility fixes | üü¢ Positive ‚Äî 50% VRAM reduction means we could increase batch size or use higher LoRA rank | Easy |
| 3 | **PEFT** | DeLoRA, RoAd, ALoRA, weight tying, Transformers v5 compat | ‚â•0.18.1 | v0.18.0: 6 new PEFT methods (RoAd, ALoRA, Arrow, WaveFT, DeLoRA, OSF), `ensure_weight_tying` for `modules_to_save`, dropped Python 3.9. v0.18.1: Transformers v5 fixes | üü¢ Positive ‚Äî DeLoRA/RoAd may outperform standard LoRA; weight tying fixes our lm_head/embed_tokens setup | Easy |
| 4 | **PEFT** | SHiRA, MiSS, LoRA for MoE | 0.17.0 | SHiRA (Sparse High Rank Adapters) trains 1-2% of weights directly, MiSS (Matrix Shard Sharing) replaces Bone, LoRA can target `nn.Parameter` for MoE layers | üü° Neutral ‚Äî SHiRA is interesting alternative to LoRA but untested on medical VLMs | Easy |
| 5 | **PEFT** | LoRA-FA, RandLoRA, C¬≥A, QA-LoRA | 0.16.0 | LoRA-FA optimizer reduces memory via frozen A matrix, RandLoRA approximates full-rank updates, Quantization-Aware LoRA training (GPTQ only). VLM layer refactor compatibility | üü° Neutral ‚Äî LoRA-FA could save memory, QA-LoRA not yet for NF4 | Easy |
| 6 | **BitsAndBytes** | 8-bit bitsandbytes v0.45.0+ improvements | ‚â•0.45.0 | Improved 8-bit quantization, paged optimizer enhancements. Already used in v2 for `paged_adamw_8bit` | üü° Neutral ‚Äî already using these features | None |
| 7 | **PyTorch** | 2.x series updates | ‚â•2.4 | Required by Transformers v5. `torch.compile` improvements, `scaled_dot_product_attention` enhancements, memory-efficient attention, `expandable_segments` | üü¢ Positive ‚Äî better compiled training, memory efficiency | Easy |
| 8 | **Accelerate** | Multi-GPU and mixed precision | latest | Improved device_map, better quantization support, FSDP improvements | üü° Neutral ‚Äî single GPU setup, but useful for future scaling | None |
| 9 | **vLLM** | v0.12 support in TRL | ‚â•0.12 | Fast inference serving with continuous batching, TRL integration for on-policy training | üü¢ Positive ‚Äî enables fast inference serving for API endpoint | Medium |

---

#### A1.3 Dataset Developments

| # | Dataset | Size | Modality | Labels | Localization? | Access | Relevance |
|---|---------|------|----------|--------|--------------|--------|-----------|
| 1 | **PadChest** (current) ‚≠ê | 160K+ images | CXR | 174 findings, 104 locations | Text-based anatomical labels | Open (BIMCV) | ‚≠ê Primary ‚Äî our training dataset |
| 2 | **Chest ImaGenome** | 242K bounding boxes for MIMIC-CXR | CXR | Scene graphs linking findings to anatomical regions | ‚úÖ Bounding boxes + scene graphs | PhysioNet | ‚¨ÜÔ∏è High ‚Äî MedGemma 1.5 trained on this; provides real bounding box annotations we could use for localization fine-tuning |
| 3 | **MIMIC-CXR v2.1.0** | 377K images, 227K reports | CXR | Free-text radiology reports | Via RadGraph extraction | PhysioNet (credentialing required) | ‚¨ÜÔ∏è High ‚Äî gold standard CXR dataset with radiologist reports, used for RadGraph F1 evaluation |
| 4 | **CheXpert** | 224K images | CXR | 14 observation labels (with uncertainty) | No pixel-level | Stanford DUA | ‚û°Ô∏è Medium ‚Äî useful for evaluation benchmark, requires DUA |
| 5 | **NIH ChestX-ray14** | 112K images | CXR | 14 pathology labels | Bounding boxes for 880 images | Open (NIH) | ‚û°Ô∏è Medium ‚Äî smaller than PadChest, limited localization |
| 6 | **VinDr-CXR** | 18K images | CXR | 28 findings | ‚úÖ Radiologist bounding boxes (3 annotators) | Open (PhysioNet) | ‚¨ÜÔ∏è High ‚Äî high-quality bounding box annotations by radiologists, excellent for localization validation |
| 7 | **CT-RATE** | 50K CT volumes | CT | 18 conditions/abnormalities | 3D volume-level | Open (HuggingFace) | ‚¨áÔ∏è Low ‚Äî CT not CXR, but MedGemma 1.5 supports 3D; future expansion |
| 8 | **MS-CXR-T** | Temporal CXR pairs | CXR | Disease progression labels | Longitudinal comparison | PhysioNet | ‚û°Ô∏è Medium ‚Äî MedGemma 1.5 supports longitudinal CXR; could enable disease progression tracking |

---

### A2. Research Papers (2024 ‚Äì Feb 2026)

#### A2.1 Medical Vision-Language Models

| # | Title | Authors | Year | Venue | Key Contribution | Applicability to v3 | Difficulty | arXiv / DOI |
|---|-------|---------|------|-------|------------------|---------------------|------------|-------------|
| 1 | **MedGemma Technical Report** ‚≠ê | Sellergren et al. | 2025 | arXiv | Medical SigLIP vision encoder pre-trained on CXR/derm/ophth/histo + Gemma 3 decoder. Establishes MedGemma architecture and fine-tuning methodology | üéØ Direct ‚Äî our base model paper, fine-tuning recipes directly applicable | Easy | arXiv:2507.05201 |
| 2 | CheXagent: Towards a Foundation Model for Chest X-Ray Interpretation | Chen et al. | 2024 | arXiv | CXR-specific agent with structured report generation, Phi backbone, multi-task training on 28+ CXR datasets | üéØ Direct ‚Äî ensemble candidate, report format comparable to ours | Medium | arXiv:2401.12208 |
| 3 | LLaVA-Med: Training a Large Language-and-Vision Assistant for Biomedicine in One Day | Li et al. | 2023 | NeurIPS | Biomedical VLM via self-instruct from PubMed figure-caption pairs. Demonstrated VLM adaptation to medical domain | üîÑ Indirect ‚Äî methodology for medical VLM training, but model outdated | N/A | arXiv:2306.00890 |
| 4 | BiomedCLIP: A Multimodal Biomedical Foundation Model | Zhang et al. | 2023 | arXiv | CLIP model trained on PMC-15M biomedical figure-caption pairs. PubMedBERT text + ViT vision | üîÑ Indirect ‚Äî useful for CXR embedding/retrieval and image quality scoring | Easy | arXiv:2303.00915 |
| 5 | MedXpertQA: Benchmarking Expert-Level Medical Reasoning and Understanding | Zuo et al. | 2025 | arXiv | Expert-level medical QA benchmark with multimodal questions. MedGemma 1.5 evaluated on this | üîÑ Indirect ‚Äî evaluation benchmark for medical reasoning capability | Easy | arXiv:2501.18362 |
| 6 | Med-Flamingo: A Multimodal Medical Few-shot Learner | Moor et al. | 2023 | ML4H | Few-shot medical VLM based on Flamingo architecture, strong at in-context learning with medical images | üí° Inspirational ‚Äî few-shot approach could supplement fine-tuning for rare findings | Hard | arXiv:2307.15189 |
| 7 | RadFM: A Radiology Foundation Model | Wu et al. | 2023 | arXiv | 3D/2D radiology foundation model trained on large-scale radiology datasets | üí° Inspirational ‚Äî 3D radiology support, but model availability limited | Hard | arXiv:2308.02463 |
| 8 | BiomedGPT: A Unified and Generalist Biomedical Generative Pre-trained Transformer | Zhang et al. | 2023 | arXiv | Multi-task biomedical model covering VQA, report generation, classification across modalities | üí° Inspirational ‚Äî multi-task training strategy for medical AI | Hard | arXiv:2305.17100 |
| 9 | PaliGemma: A versatile 3B VLM for transfer | Steiner et al. | 2024 | arXiv | SigLIP + Gemma architecture enabling efficient transfer. Foundation for MedGemma | üîÑ Indirect ‚Äî understanding base architecture helps optimize fine-tuning | N/A | arXiv:2407.07726 |

---

#### A2.2 Disease Localization & Grounding

| # | Title | Authors | Year | Venue | Key Contribution | Applicability to v3 | Difficulty | arXiv / DOI |
|---|-------|---------|------|-------|------------------|---------------------|------------|-------------|
| 1 | **Segment Anything in Medical Images (MedSAM)** ‚≠ê | Ma et al. | 2024 | Nature Communications | SAM adapted for medical imaging with 1.6M image-mask pairs across 11 modalities. Prompting-based segmentation | üéØ Direct ‚Äî replace 26-region bounding boxes with pixel-accurate masks | Medium | arXiv:2304.12306 |
| 2 | Segment Anything (SAM) | Kirillov et al. | 2023 | ICCV | Foundation segmentation model, 1B+ masks, prompt-based. Basis for MedSAM | üîÑ Indirect ‚Äî foundational but not medical-specific | Easy | arXiv:2304.02643 |
| 3 | SAM 2: Segment Anything in Images and Videos | Ravi et al. | 2024 | arXiv | Improved SAM with video support, better efficiency, streaming architecture | üîÑ Indirect ‚Äî MedSAM-Agent uses SAM2 for medical segmentation | Medium | arXiv:2408.00714 |
| 4 | Grounding DINO: Marrying DINO with Grounded Pre-Training | Liu et al. | 2023 | ECCV | Open-set object detection with text-grounding. Can detect objects from text descriptions | üéØ Direct ‚Äî text-grounded localization: "find pleural effusion" ‚Üí bounding box | Medium | arXiv:2303.05499 |
| 5 | Grad-CAM: Visual Explanations from Deep Networks | Selvaraju et al. | 2017 | ICCV | Gradient-weighted class activation mapping for CNN interpretability | üéØ Direct ‚Äî generate attention heatmaps from MedGemma's vision encoder for visual explanations | Easy | arXiv:1610.02391 |
| 6 | Chest ImaGenome Dataset for Clinical Reasoning | Wu et al. | 2021 | PhysioNet | 242K bounding boxes linking anatomical regions to findings in MIMIC-CXR images via scene graphs | üéØ Direct ‚Äî MedGemma 1.5 trained on this (IoU: 38.0). Provides bounding box ground truth for CXR | Easy | doi:10.13026/wv01-y230 |
| 7 | MIMIC-CXR Radiograph Labels Adjudication | Yang et al. | 2024 | arXiv | Radiologist-adjudicated labels for MIMIC-CXR, improving label quality for evaluation | üîÑ Indirect ‚Äî better evaluation ground truth | Easy | arXiv:2405.03162 |

---

#### A2.3 Fine-tuning & Training Techniques

| # | Title | Authors | Year | Venue | Key Contribution | Applicability to v3 | Difficulty | arXiv / DOI |
|---|-------|---------|------|-------|------------------|---------------------|------------|-------------|
| 1 | **QLoRA: Efficient Finetuning of Quantized LLMs** ‚≠ê | Dettmers et al. | 2023 | NeurIPS | 4-bit NF4 quantization + LoRA adapters, paged optimizers. Enables fine-tuning 65B models on single GPU | üéØ Direct ‚Äî our core fine-tuning method. v2 already uses this | N/A | arXiv:2305.14314 |
| 2 | **DoRA: Weight-Decomposed Low-Rank Adaptation** | Liu et al. | 2024 | ICML | Decomposes LoRA into magnitude and direction components, consistently outperforms LoRA across tasks | üéØ Direct ‚Äî drop-in replacement for LoRA in PEFT, may improve accuracy by 1-3% | Easy | arXiv:2402.09353 |
| 3 | DeLoRA: Decoupled Low-Rank Adaptation | Bini et al. | 2025 | arXiv | Similar to DoRA but with constrained norm deviation, prevents divergence better than DoRA | üéØ Direct ‚Äî available in PEFT ‚â•0.18.0, potential accuracy improvement | Easy | arXiv:2503.18225 |
| 4 | RoAd: 2D Rotary Adaptation | Petrushkov et al. | 2024 | arXiv | Learns 2D rotation matrices applied via element-wise multiplication. Very fast inference, supports mixed adapter batches | üîÑ Indirect ‚Äî interesting for multi-adapter scenarios but untested on medical VLMs | Medium | arXiv:2409.00119 |
| 5 | SHiRA: Sparse High Rank Adapters | KKB et al. | 2024 | arXiv | Trains 1-2% of weights directly (sparse), reduced concept loss with multiple adapters | üí° Inspirational ‚Äî could be better than LoRA for domain adaptation, but new | Medium | arXiv:2406.13175 |
| 6 | LoRA: Low-Rank Adaptation of Large Language Models | Hu et al. | 2021 | ICLR | Foundational PEFT method: BA low-rank decomposition of weight updates, frozen base model | üéØ Direct ‚Äî our current method (r=32, Œ±=64, all-linear) | N/A | arXiv:2106.09685 |
| 7 | VeRA: Vector-based Random Matrix Adaptation | Kopiczko et al. | 2023 | ICLR | Non-learnable random bases + learnable scaling. Extreme parameter efficiency | üí° Inspirational ‚Äî 10√ó fewer trainable params than LoRA, but may sacrifice accuracy | Easy | arXiv:2310.11454 |

---

#### A2.4 Evaluation & Clinical Validation

| # | Title | Authors | Year | Venue | Key Contribution | Applicability to v3 | Difficulty | arXiv / DOI |
|---|-------|---------|------|-------|------------------|---------------------|------------|-------------|
| 1 | **RadGraph: Extracting Clinical Entities and Relations from Radiology Reports** ‚≠ê | Jain et al. | 2021 | NeurIPS (Datasets) | Knowledge graph extraction from radiology reports. Enables RadGraph F1 metric ‚Äî the industry standard for report generation quality | üéØ Direct ‚Äî add RadGraph F1 as primary evaluation metric alongside soft match accuracy | Medium | arXiv:2106.14463 |
| 2 | CheXpert: A Large Chest Radiograph Dataset with Uncertainty Labels | Irvin et al. | 2019 | AAAI | 224K CXR with 14 observations, uncertainty-aware labeling. De facto CXR evaluation benchmark | üéØ Direct ‚Äî standard benchmark for CXR classification evaluation | Easy | arXiv:1901.07031 |
| 3 | MedXpertQA: Benchmarking Expert-Level Medical Reasoning | Zuo et al. | 2025 | arXiv | Expert-level multimodal medical QA. MedGemma 1.5 scores 20.9% (4B) vs 26.8% (27B) | üîÑ Indirect ‚Äî general medical reasoning benchmark, not CXR-specific | Easy | arXiv:2501.18362 |
| 4 | CheXzero: Health-aware Contrastive Learning for CXR | Tiu et al. | 2022 | Nature BME | Zero-shot CXR classification using CLIP-style contrastive learning. No task-specific labels needed | üí° Inspirational ‚Äî zero-shot approach for findings we lack labeled data for | Medium | arXiv:2205.09785 |
| 5 | Adjudicated Labels for MIMIC-CXR | Yang et al. | 2024 | arXiv | Radiologist adjudication of automated CXR labels, improving evaluation ground truth reliability | üéØ Direct ‚Äî higher-quality labels for evaluation; MedGemma uses these for benchmarking | Easy | arXiv:2405.03162 |

---

#### A2.5 Top 5 Must-Read Papers

| Rank | Paper | Why It's Critical for ExplainMyXray v2‚Üív3 |
|------|-------|-------------------------------------------|
| 1 | **MedGemma Technical Report** (arXiv:2507.05201) | Our base model paper. Contains fine-tuning recipes, benchmark methodology, and confirms MedGemma 1.5's native bounding box capability (IoU 38.0). Essential reading for v3 upgrade. |
| 2 | **RadGraph** (arXiv:2106.14463) | Defines the industry-standard RadGraph F1 metric for radiology report evaluation. v2 uses only soft-match accuracy; v3 must add RadGraph F1 to be taken seriously. |
| 3 | **MedSAM** (arXiv:2304.12306) | Pixel-accurate medical segmentation. Replaces our crude 26-region text‚Üíbox mapping with precise anatomical segmentation masks on CXR images. |
| 4 | **DoRA** (arXiv:2402.09353) | Drop-in LoRA replacement in PEFT that consistently outperforms standard LoRA. Could push us from 95% toward 97%+ accuracy with zero VRAM increase. |
| 5 | **QLoRA** (arXiv:2305.14314) | Foundational method we already use. Re-reading confirms our NF4 + double quant + paged optimizer setup is optimal. Focus on the forward_masked_logits addition from TRL. |

---

### A3. Open-Source Multimodal Models for Integration

#### A3.1 Primary Model Candidates

| # | Model | HuggingFace ID | Params | VRAM (4-bit) | Vision Encoder | LLM Decoder | Medical Pre-training | CXR Perf | Fine-tunable (LoRA) | License | Verdict |
|---|-------|---------------|--------|-------------|----------------|-------------|---------------------|----------|--------------------|---------|---------| 
| 1 | **MedGemma 1.5 4B-it** ‚≠ê | `google/medgemma-1.5-4b-it` | 4B | ~2.5 GB | Medical SigLIP 896¬≤ | Gemma 3 | ‚úÖ CXR, Derm, Ophth, Histo, CT, MRI | MIMIC F1=89.5, CheXpert=48.2, IoU=38.0 | ‚úÖ | HAI-DEF License | **‚≠ê UPGRADE ‚Äî Primary choice for v3** |
| 2 | MedGemma 1.0.1 4B-it | `google/medgemma-4b-it` | 4B | ~2.5 GB | Medical SigLIP 896¬≤ | Gemma 3 | ‚úÖ CXR, Derm, Ophth, Histo | MIMIC F1=88.9, CheXpert=48.1, IoU=3.1 | ‚úÖ | HAI-DEF License | Keep as fallback |
| 3 | CheXagent-2-3b | `StanfordAIMI/CheXagent-2-3b` | 3B | ~1.5 GB | Custom (Phi-based) | Phi | ‚úÖ CXR-specific (28+ datasets) | Strong CXR report generation | ‚úÖ | MIT | **Ensemble candidate** |
| 4 | LLaVA-Med 7B | `microsoft/llava-med-7b-delta` | 7B | ~4 GB | CLIP ViT-L/14 | LLaMA | ‚úÖ PubMed biomedical | Moderate VQA | ‚úÖ (tight) | LLaMA License | Skip ‚Äî 7B tight, old CLIP encoder |
| 5 | PaliGemma 2 3B | `google/paligemma2-3b-pt-896` | 3B | ~1.5 GB | SigLIP 896¬≤ | Gemma | ‚ùå None | Low (general) | ‚úÖ | Gemma License | Skip ‚Äî no medical pretraining |
| 6 | BiomedGPT | Community fine-tunes | ~3-7B | ~2-4 GB | Various | Various | ‚úÖ Biomedical multi-task | Mixed | Varies | Various | Skip ‚Äî fragmented, no official release |
| 7 | RadFM | Research only | 14B | ~7 GB | Custom 3D/2D | LLaMA | ‚úÖ Radiology | Unknown (research) | Limited | Research | Skip ‚Äî too large, limited availability |
| 8 | Med-Flamingo | Research only | 9B | ~5 GB | CLIP + cross-attn | LLaMA | ‚úÖ Medical few-shot | Few-shot strong | Limited | Research | Skip ‚Äî 9B too large, research only |
| 9 | Phi-4-multimodal | `microsoft/Phi-4-multimodal-instruct` | 5.6B | ~3 GB | Custom | Phi-4 | ‚ùå None | Low (general) | ‚úÖ | MIT | Watch ‚Äî efficient but no medical data |
| 10 | InternVL2-8B | `OpenGVLab/InternVL2-8B` | 8B | ~5 GB | InternViT-6B | InternLM2 | ‚ùå None | Moderate (general) | ‚úÖ (tight) | Apache 2.0 | Skip ‚Äî 8B won't fit for training |
| 11 | Qwen2.5-VL-7B | `Qwen/Qwen2.5-VL-7B-Instruct` | 7B | ~4 GB | Custom dynamic res | Qwen2.5 | ‚ùå None | Moderate (general) | ‚úÖ (tight) | Apache 2.0 | Skip ‚Äî 7B tight, no medical data |
| 12 | BiomedCLIP | `microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224` | 0.2B | <1 GB | ViT-B/16 | PubMedBERT | ‚úÖ PMC-15M biomedical | N/A (embedding) | ‚úÖ | MIT | **Use as auxiliary** (retrieval/quality) |

**Per-Model Assessments:**

**MedGemma 1.5 4B-it** ‚≠ê
```
Strengths: Native bounding box localization (IoU 38.0 vs v1's 3.1), longitudinal CXR support, improved CXR accuracy (F1 89.5 vs 88.9), 3D CT/MRI support, same 4B params / 2.5 GB VRAM, document understanding (EHR PDF‚ÜíJSON). 424 likes, 161K downloads.
Weaknesses: Slightly lower SLAKE VQA score than v1 (59.7 vs 72.3 ‚Äî less optimized for Q&A format), still requires fine-tuning for specific use cases, greedy decoding default may reduce output diversity.
Integration path: Drop-in replacement. Change model_id from "google/medgemma-4b-it" to "google/medgemma-1.5-4b-it" in notebook Cell 5. Same QLoRA config works. Add bounding box extraction from model outputs for native localization.
```

**CheXagent-2-3b**
```
Strengths: CXR-specific training on 28+ datasets, 3B params (fits easily in 12 GB), MIT license, structured report generation (srrg-findings variant), Stanford AIMI backing. Only 1.5 GB at 4-bit.
Weaknesses: Based on older Phi architecture, requires trust_remote_code=True, transformers compatibility pinned to 4.40.0, smaller community (2.2K downloads), not multimodal outside CXR.
Integration path: Ensemble approach ‚Äî run both MedGemma 1.5 and CheXagent, merge findings with confidence voting. Or use as evaluation cross-reference.
```

**Phi-4-multimodal**
```
Strengths: Small (5.6B), MIT license, strong reasoning, Microsoft backing, efficient architecture with vision + speech + text.
Weaknesses: No medical pretraining whatsoever. 5.6B is manageable but tighter than 4B for 12 GB QLoRA. Would need full medical fine-tuning from scratch.
Integration path: Only worthwhile if fine-tuned on medical data. Monitor for medical fine-tuned variants from the community.
```

---

#### A3.2 Auxiliary Models (Enhance Specific Pipeline Stages)

| # | Model | Task | HuggingFace ID / GitHub | Params | VRAM | How It Enhances Our Pipeline | Integration Effort | Priority |
|---|-------|------|------------------------|--------|------|-----------------------------|--------------------|----------|
| 1 | **MedSAM** ‚≠ê | Medical image segmentation | `wanglab/medsam-vit-base` | 93M | <1 GB | Replace 26-region text‚Üíbox mapping with pixel-accurate segmentation masks. Prompt with bounding box from MedGemma 1.5 ‚Üí get precise mask | Medium | üî¥ HIGH |
| 2 | **BiomedCLIP** | Medical image embedding / retrieval | `microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224` | 200M | <1 GB | Image quality pre-screening (reject blurry/rotated X-rays), similar-case retrieval for RAG, embedding-based evaluation | Easy | üü° MEDIUM |
| 3 | **CheXbert** | CXR report label extraction | `stanfordmlgroup/CheXbert` or via `f1chexbert` package | ~110M | <1 GB | Extract standardized 14 CheXpert labels from generated reports for automated evaluation. Industry-standard metric | Easy | üî¥ HIGH |
| 4 | **RadGraph** | Report entity/relation extraction | Via `radgraph` package (arXiv:2106.14463) | ~340M | ~1 GB | Extract clinical entities and relations from reports ‚Üí compute RadGraph F1 score. The gold standard metric for report generation | Medium | üî¥ HIGH |
| 5 | **Grounding DINO** | Text-grounded object detection | `IDEA-Research/grounding-dino-base` | 172M | ~1 GB | Text prompt "find pleural effusion" ‚Üí bounding box on CXR. Alternative to MedGemma's native bbox for specific findings | Medium | üü° MEDIUM |
| 6 | **MedSAM 2 / SAM 2** | Real-time segmentation | `facebook/sam2-hiera-large` + medical fine-tune | 224M | ~1 GB | Next-gen SAM with improved efficiency and video support. Medical fine-tunes emerging | Medium | üü¢ NICE |
| 7 | **TorchXRayVision** | CXR classification & preprocessing | `mlmed/torchxrayvision` (GitHub/PyPI) | Various | <1 GB | Pre-trained CXR classifiers (DenseNet, ResNet) for baseline comparison, image normalization, dataset loading utilities | Easy | üü° MEDIUM |
| 8 | **Medical Diffusion** | CXR augmentation / synthesis | Various (e.g., `RoentGen`) | ~1B | ~2 GB | Generate synthetic CXR images for data augmentation, especially for rare findings. Diffusion-based medical image generation | Hard | üü¢ NICE |

---

#### A3.3 Emerging Architectures & Techniques

| # | Architecture / Technique | Example Models | Key Innovation | Feasibility on 12 GB | Expected Accuracy Gain | Timeline to Adopt |
|---|------------------------|----------------|----------------|---------------------|----------------------|-------------------|
| 1 | **forward_masked_logits** ‚≠ê | TRL ‚â•0.27.0 | Only compute logits for tokens present in batch, not full vocabulary. Up to 50% VRAM reduction during forward pass | ‚úÖ Already available ‚Äî just enable in SFTConfig | +0% accuracy, but unlocks higher batch size or LoRA rank ‚Üí indirect +1-3% | **Short ‚Äî This week** |
| 2 | **DoRA / DeLoRA** | PEFT ‚â•0.18.0 | Decomposes weight updates into magnitude and direction. Better than standard LoRA on most benchmarks | ‚úÖ Drop-in replacement, same VRAM | +1-3% accuracy improvement | **Short ‚Äî 1 day** |
| 3 | **MedGemma 1.5 native bounding boxes** | MedGemma 1.5 4B-it | Model directly predicts bounding box coordinates (IoU 38.0 on Chest ImaGenome) vs our text‚Üícoordinate mapping | ‚úÖ Same VRAM | Dramatically better localization | **Short ‚Äî 2 days** |
| 4 | **RAG with medical knowledge bases** | Any VLM + vector DB | Retrieve relevant radiology textbook passages / similar cases during inference. Ground model's knowledge | ‚úÖ Vector DB is CPU, only embedding model on GPU (<1 GB) | +3-5% on rare findings via retrieved context | **Medium ‚Äî 2 weeks** |
| 5 | **Mixture of Experts (MoE)** | Gemma 3 MoE variants, EXAONE-MoE | Activate subset of parameters per token, enabling larger capacity at same compute cost | ‚ö†Ô∏è MoE models tend to be larger; need 4-bit quantization | +5-10% capacity but VRAM uncertain | **Long ‚Äî 3+ months** |
| 6 | **State-space models (Mamba)** | Mamba2, Jamba | Linear-time attention alternative for long sequences. Efficient for long medical reports | ‚ö†Ô∏è Not yet integrated with medical VLMs | Unknown for medical VLMs | **Long ‚Äî 6+ months** |
| 7 | **Multi-agent medical AI** | MedRAX, specialist agents | Multiple specialist models (one per finding type) coordinated by an agent | ‚ö†Ô∏è Multiple models on 12 GB is challenging; need CPU offloading | +5-10% on complex multi-finding cases | **Long ‚Äî 3+ months** |
| 8 | **Diffusion-based CXR augmentation** | RoentGen, medical stable diffusion | Generate synthetic CXR with specific pathologies for training data augmentation | ‚úÖ Generate offline, no runtime VRAM cost | +1-5% accuracy on rare findings | **Medium ‚Äî 1 month** |

---

## Part B: Deliverables

---

### B1. Complete VS Code Project File Structure (ExplainMyXray v3)

```
ExplainMyXray/
‚îú‚îÄ‚îÄ üìÅ .vscode/
‚îÇ   ‚îú‚îÄ‚îÄ settings.json                    # Python env, linting (Ruff), formatters (Black), Pylance config
‚îÇ   ‚îú‚îÄ‚îÄ launch.json                      # Debug configs: notebook, FastAPI server, pytest, single-file
‚îÇ   ‚îú‚îÄ‚îÄ extensions.json                  # Required: Python, Jupyter, Pylance, Ruff, GitLens, TensorBoard
‚îÇ   ‚îî‚îÄ‚îÄ tasks.json                       # Build/train/eval/serve task runners with keyboard shortcuts
‚îÇ
‚îú‚îÄ‚îÄ üìÅ .github/
‚îÇ   ‚îú‚îÄ‚îÄ workflows/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ci.yml                       # CI: lint (Ruff), type-check (Pyright), unit tests (pytest)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ model-test.yml               # Model integration tests on push to main
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ release.yml                  # Automated release with adapter upload to HuggingFace Hub
‚îÇ   ‚îú‚îÄ‚îÄ ISSUE_TEMPLATE/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bug_report.md                # Bug report template
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ feature_request.md           # Feature request template
‚îÇ   ‚îî‚îÄ‚îÄ PULL_REQUEST_TEMPLATE.md         # PR template with checklist
‚îÇ
‚îú‚îÄ‚îÄ üìÅ configs/
‚îÇ   ‚îú‚îÄ‚îÄ model/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ medgemma_1.5_4b.yaml         # MedGemma 1.5 4B-it model config (primary)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ medgemma_4b.yaml             # MedGemma 1.0 4B-it model config (fallback)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ chexagent_3b.yaml            # CheXagent-2-3b ensemble config
‚îÇ   ‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ qlora_rtx4080.yaml           # QLoRA config for RTX 4080 Laptop 12 GB: r=32, Œ±=64, batch=1
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ qlora_rtx4080_dora.yaml      # DoRA variant config for accuracy experiments
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ qlora_colab_t4.yaml          # Fallback config for Colab T4 16 GB
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ hyperparameter_search.yaml   # Optuna hyperparameter search space definition
‚îÇ   ‚îú‚îÄ‚îÄ evaluation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ eval_metrics.yaml            # Metric configs: soft-match, RadGraph F1, CheXbert, per-finding
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ eval_datasets.yaml           # Evaluation dataset configs (PadChest test, VinDr-CXR)
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ padchest.yaml                # PadChest dataset config: paths, splits, finding categories
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ augmentation.yaml            # Augmentation pipeline config: rotations, contrast, synthetic
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ curriculum.yaml              # Curriculum learning config: difficulty scoring weights
‚îÇ   ‚îú‚îÄ‚îÄ localization/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bbox_regions.yaml            # 26 anatomical region ‚Üí bounding box coordinate mapping
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ medsam_config.yaml           # MedSAM integration config: model path, threshold, device
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ visualization.yaml           # Overlay rendering config: colors, opacity, font sizes
‚îÇ   ‚îú‚îÄ‚îÄ serving/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ api_config.yaml              # FastAPI server config: host, port, CORS, rate limits
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ gradio_config.yaml           # Gradio demo config: theme, examples, sharing
‚îÇ   ‚îî‚îÄ‚îÄ monitoring/
‚îÇ       ‚îú‚îÄ‚îÄ wandb_config.yaml            # Weights & Biases project config
‚îÇ       ‚îî‚îÄ‚îÄ alerts.yaml                  # Performance alert thresholds (accuracy drop, latency spike)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ src/
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                      # Package init with version: __version__ = "3.0.0"
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                  # Data module exports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ dataset.py                   # PadChestDataset class: CSV parsing, label splitting, chat template
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ collator.py                  # Custom DataCollator: chat template + label masking for SFTTrainer
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocessing.py             # safe_parse_list(), split_findings_locations(), compute_difficulty()
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ augmentation.py              # CXR-specific augmentations: rotation, contrast, histogram eq
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ streaming.py                 # Drive streaming for 1 TB dataset: lazy loading, caching
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ synthetic.py                 # Synthetic data generation interface for rare findings
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ validation.py               # Data quality checks: image readability, label consistency
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ model/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                  # Model module exports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ config.py                    # ModelConfig dataclass: model_id, quant config, LoRA config
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ loader.py                    # load_model(): 4-bit NF4 quantization, LoRA injection, device_map
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ quantization.py              # BitsAndBytesConfig builder: NF4, double quant, BF16 compute
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ lora.py                      # LoRA/DoRA/DeLoRA config builder with target_modules resolution
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ ensemble.py                  # Multi-model ensemble: MedGemma + CheXagent confidence voting
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ export.py                    # Adapter export to HuggingFace Hub, GGUF conversion
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ training/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                  # Training module exports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ trainer.py                   # SFTTrainer wrapper with forward_masked_logits, curriculum support
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ callbacks.py                 # EarlyStoppingCallback, AccuracyGateCallback, VRAMMonitorCallback
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ curriculum.py                # Curriculum learning: easy‚Üíhard sorting, difficulty bucketing
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ scheduler.py                 # Custom LR schedulers: cosine with warmup, one-cycle
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ distributed.py              # Multi-GPU / FSDP utilities (future-proofing)
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ evaluation/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                  # Evaluation module exports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ metrics.py                   # Core metrics: exact_match, soft_match, micro_P_R_F1
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ radgraph_eval.py             # RadGraph F1 computation from generated reports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ chexbert_eval.py             # CheXbert label extraction and F1 computation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ clinical_eval.py             # Clinical relevance scoring, per-finding breakdown
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ report_parser.py             # Parse structured FINDINGS/LOCATIONS/IMPRESSION from text
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ localization/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                  # Localization module exports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ bbox.py                      # Text anatomical label ‚Üí bounding box coordinate mapping (26 regions)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ native_bbox.py               # MedGemma 1.5 native bounding box extraction from model output
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ medsam.py                    # MedSAM integration: prompt with bbox ‚Üí pixel-accurate mask
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ heatmap.py                   # GradCAM / attention rollout heatmap generation
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ overlay.py                   # Color-coded overlay rendering with matplotlib
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ regions.py                   # Anatomical region definitions and coordinate constants
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ inference/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                  # Inference module exports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ predictor.py                 # Single-image predict_xray() with auto-visualization
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ batch.py                     # Batch inference with progress bar and output collection
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ postprocess.py              # Output parsing, confidence scoring, finding deduplication
‚îÇ   ‚îú‚îÄ‚îÄ üìÅ visualization/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                  # Visualization module exports
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ report_viz.py               # Side-by-side X-ray visualization (original + annotated)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ training_curves.py           # Loss, accuracy, learning rate plots from training logs
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ finding_distribution.py      # Dataset finding frequency analysis and plots
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ dashboard.py                # Interactive Plotly dashboard for model performance
‚îÇ   ‚îî‚îÄ‚îÄ üìÅ api/
‚îÇ       ‚îú‚îÄ‚îÄ __init__.py                  # API module exports
‚îÇ       ‚îú‚îÄ‚îÄ routes.py                    # FastAPI routes: /predict, /batch, /health, /model-info
‚îÇ       ‚îú‚îÄ‚îÄ schemas.py                   # Pydantic schemas: PredictionRequest, PredictionResponse
‚îÇ       ‚îú‚îÄ‚îÄ middleware.py                # CORS, rate limiting, authentication middleware
‚îÇ       ‚îî‚îÄ‚îÄ gradio_app.py               # Gradio web UI for interactive X-ray analysis demo
‚îÇ
‚îú‚îÄ‚îÄ üìÅ notebooks/
‚îÇ   ‚îú‚îÄ‚îÄ 01_train_medgemma_v3.ipynb       # Main training notebook: MedGemma 1.5 + QLoRA + DoRA
‚îÇ   ‚îú‚îÄ‚îÄ 02_evaluate_model.ipynb          # Comprehensive evaluation: soft-match + RadGraph F1 + per-finding
‚îÇ   ‚îú‚îÄ‚îÄ 03_localization_demo.ipynb       # MedGemma 1.5 native bbox + MedSAM mask demo
‚îÇ   ‚îú‚îÄ‚îÄ 04_interactive_demo.ipynb        # Interactive predict_xray() with visualization
‚îÇ   ‚îú‚îÄ‚îÄ 05_model_comparison.ipynb        # Compare v2 vs v3, MedGemma 1.0 vs 1.5 benchmarks
‚îÇ   ‚îî‚îÄ‚îÄ 06_data_exploration.ipynb        # PadChest dataset exploration, finding distributions
‚îÇ
‚îú‚îÄ‚îÄ üìÅ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ train.py                         # CLI training script: python scripts/train.py --config configs/...
‚îÇ   ‚îú‚îÄ‚îÄ evaluate.py                      # CLI evaluation: python scripts/evaluate.py --adapter path/...
‚îÇ   ‚îú‚îÄ‚îÄ predict.py                       # CLI single-image prediction: python scripts/predict.py --image x.png
‚îÇ   ‚îú‚îÄ‚îÄ batch_predict.py                 # CLI batch prediction over directory of images
‚îÇ   ‚îú‚îÄ‚îÄ export_adapter.py               # Export LoRA adapter to HuggingFace Hub
‚îÇ   ‚îú‚îÄ‚îÄ serve.py                         # Start FastAPI server: python scripts/serve.py --port 8000
‚îÇ   ‚îú‚îÄ‚îÄ gradio_demo.py                   # Start Gradio demo: python scripts/gradio_demo.py
‚îÇ   ‚îú‚îÄ‚îÄ data_prep.py                     # PadChest data preparation: CSV parsing, split, quality checks
‚îÇ   ‚îî‚îÄ‚îÄ benchmark.py                     # Run full benchmark suite and generate comparison report
‚îÇ
‚îú‚îÄ‚îÄ üìÅ tests/
‚îÇ   ‚îú‚îÄ‚îÄ conftest.py                      # Pytest fixtures: sample images, mock models, temp dirs
‚îÇ   ‚îú‚îÄ‚îÄ test_data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sample_xray.png              # Test X-ray image (small, for CI)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sample_labels.csv            # Test CSV with PadChest-format labels
‚îÇ   ‚îú‚îÄ‚îÄ test_preprocessing.py            # Tests for safe_parse_list, split_findings_locations, difficulty
‚îÇ   ‚îú‚îÄ‚îÄ test_dataset.py                  # Tests for PadChestDataset creation and iteration
‚îÇ   ‚îú‚îÄ‚îÄ test_model_loading.py            # Tests for model + LoRA loading (mocked for CI)
‚îÇ   ‚îú‚îÄ‚îÄ test_evaluation.py              # Tests for metric computation: soft-match, P/R/F1
‚îÇ   ‚îú‚îÄ‚îÄ test_localization.py            # Tests for bbox mapping, overlay rendering
‚îÇ   ‚îú‚îÄ‚îÄ test_report_parser.py           # Tests for FINDINGS/LOCATIONS/IMPRESSION parsing
‚îÇ   ‚îî‚îÄ‚îÄ test_api.py                     # Tests for FastAPI routes (with TestClient)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ docker/
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.train                 # Training container: CUDA 12.4, PyTorch 2.x, full ML stack
‚îÇ   ‚îú‚îÄ‚îÄ Dockerfile.serve                 # Serving container: lightweight, FastAPI + model inference only
‚îÇ   ‚îî‚îÄ‚îÄ docker-compose.yml              # Compose: train + serve + TensorBoard services
‚îÇ
‚îú‚îÄ‚îÄ üìÅ docs/
‚îÇ   ‚îú‚îÄ‚îÄ architecture.md                  # System architecture documentation with Mermaid diagrams
‚îÇ   ‚îú‚îÄ‚îÄ api.md                          # API endpoint documentation with examples
‚îÇ   ‚îú‚îÄ‚îÄ training_guide.md              # Step-by-step training guide for RTX 4080 Laptop
‚îÇ   ‚îú‚îÄ‚îÄ evaluation_guide.md            # Evaluation metrics explanation and interpretation
‚îÇ   ‚îú‚îÄ‚îÄ research_notes.md              # Research findings and experiment log
‚îÇ   ‚îú‚îÄ‚îÄ DEEP_RESEARCH_REPORT.md        # This research report
‚îÇ   ‚îî‚îÄ‚îÄ changelog.md                   # Version changelog: v1 ‚Üí v2 ‚Üí v3
‚îÇ
‚îú‚îÄ‚îÄ üìÅ models/
‚îÇ   ‚îú‚îÄ‚îÄ adapters/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep                    # LoRA adapter checkpoints (gitignored, stored on HF Hub)
‚îÇ   ‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep                    # Saved model configs from training runs
‚îÇ   ‚îî‚îÄ‚îÄ checkpoints/
‚îÇ       ‚îî‚îÄ‚îÄ .gitkeep                    # Training checkpoints (gitignored, large files)
‚îÇ
‚îú‚îÄ‚îÄ üìÅ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep                    # Raw PadChest CSV (gitignored, ~200 MB)
‚îÇ   ‚îú‚îÄ‚îÄ processed/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep                    # Preprocessed splits with difficulty scores
‚îÇ   ‚îî‚îÄ‚îÄ sample/
‚îÇ       ‚îú‚îÄ‚îÄ sample_xray_pa.png          # Sample PA chest X-ray for demos
‚îÇ       ‚îú‚îÄ‚îÄ sample_xray_ap.png          # Sample AP chest X-ray for demos
‚îÇ       ‚îî‚îÄ‚îÄ sample_padchest.csv         # 100-row sample of PadChest CSV for testing
‚îÇ
‚îú‚îÄ‚îÄ üìÅ monitoring/
‚îÇ   ‚îú‚îÄ‚îÄ experiment_tracker.py           # W&B / MLflow experiment logging wrapper
‚îÇ   ‚îú‚îÄ‚îÄ drift_detector.py              # Model performance drift detection on new data
‚îÇ   ‚îî‚îÄ‚îÄ alerting.py                    # Slack/email alerts when metrics drop below threshold
‚îÇ
‚îú‚îÄ‚îÄ üìÅ assets/
‚îÇ   ‚îú‚îÄ‚îÄ sample_xrays/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep                    # Sample X-ray images for documentation
‚îÇ   ‚îú‚îÄ‚îÄ visualizations/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ .gitkeep                    # Generated visualization outputs
‚îÇ   ‚îî‚îÄ‚îÄ architecture_diagram.png       # Architecture diagram (generated from Napkin AI)
‚îÇ
‚îú‚îÄ‚îÄ .env.example                        # Template: HF_TOKEN=hf_YOUR_TOKEN_HERE, WANDB_API_KEY=...
‚îú‚îÄ‚îÄ .gitignore                          # Blocks .env, *.secret, checkpoints, __pycache__, data/raw/
‚îú‚îÄ‚îÄ .pre-commit-config.yaml            # Pre-commit hooks: Ruff lint, Black format, trailing whitespace
‚îú‚îÄ‚îÄ pyproject.toml                     # Project metadata, Ruff/Black config, pytest config, build system
‚îú‚îÄ‚îÄ requirements.txt                   # Production deps: transformers, trl, peft, bitsandbytes, etc.
‚îú‚îÄ‚îÄ requirements-dev.txt               # Dev deps: pytest, ruff, black, pre-commit, ipykernel
‚îú‚îÄ‚îÄ install.sh                         # Linux/macOS automated setup (venv, deps, GPU verify)
‚îú‚îÄ‚îÄ install.bat                        # Windows automated setup (venv, deps, GPU verify)
‚îú‚îÄ‚îÄ README.md                         # Complete project documentation with quickstart
‚îú‚îÄ‚îÄ CLAUDE_PROMPT.md                  # Vibe-coding prompt for collaborators
‚îú‚îÄ‚îÄ CLAUDE_OPUS_RESEARCH_PROMPT.md    # This research prompt template
‚îú‚îÄ‚îÄ architecture_prompt.json          # v2 architecture visualization (875 lines)
‚îî‚îÄ‚îÄ architecture_prompt_v3.json       # v3 architecture visualization (1000+ lines, research-enhanced)
```

---

### B2. Complete Tech Stack Recommendation

#### üß† 1. Core ML

| Tool | Version | Purpose | Replaces | VRAM Impact | Research Backing | Priority |
|------|---------|---------|----------|-------------|-----------------|----------|
| **PyTorch** | ‚â•2.4.0 | Deep learning framework with CUDA, BF16 tensor cores, torch.compile | PyTorch 2.x (current) | None | Required by Transformers v5 (min PyTorch 2.4) | üî¥ MUST |
| **CUDA Toolkit** | 12.4+ | GPU compute for NVIDIA RTX 4080 Laptop Ada Lovelace architecture | Same | None | RTX 4080 Laptop requires CUDA 12.x for full SM ‚â•8.0 support | üî¥ MUST |
| **cuDNN** | ‚â•9.0 | Optimized GPU primitives for convolutions, attention | Same | None | BF16 tensor core utilization | üî¥ MUST |

#### ü§ó 2. Model Libraries

| Tool | Version | Purpose | Replaces | VRAM Impact | Research Backing | Priority |
|------|---------|---------|----------|-------------|-----------------|----------|
| **Transformers** ‚≠ê | ‚â•5.1.0 | Model loading, tokenization, generation. MedGemma 1.5 support | ‚â•4.52.0 (v2) | None | v5.0 breaking changes; v5.1 adds new model architectures | üî¥ MUST |
| **TRL** ‚≠ê | ‚â•0.27.2 | SFTTrainer with forward_masked_logits for 50% VRAM reduction | ‚â•0.17.0 (v2) | -50% forward pass | arXiv:2305.14314 (QLoRA); TRL changelog | üî¥ MUST |
| **PEFT** ‚≠ê | ‚â•0.18.1 | LoRA/DoRA/DeLoRA adapters, Transformers v5 compatibility | ‚â•0.15.0 (v2) | None | arXiv:2402.09353 (DoRA), arXiv:2503.18225 (DeLoRA) | üî¥ MUST |
| **Accelerate** | ‚â•1.5.0 | Device mapping, mixed precision, model loading | ‚â•1.5.0 (v2) | None | HuggingFace ecosystem | üî¥ MUST |

#### üíæ 3. Quantization

| Tool | Version | Purpose | Replaces | VRAM Impact | Research Backing | Priority |
|------|---------|---------|----------|-------------|-----------------|----------|
| **BitsAndBytes** | ‚â•0.45.0 | 4-bit NF4 quantization + paged_adamw_8bit optimizer | Same (v2) | None (already using) | arXiv:2305.14314 (QLoRA) | üî¥ MUST |
| **Auto-GPTQ** | latest | Alternative static quantization (evaluation only) | NEW | None (eval) | For comparing GPTQ vs NF4 accuracy | üü¢ NICE |

#### üìä 4. Data Pipeline

| Tool | Version | Purpose | Replaces | VRAM Impact | Research Backing | Priority |
|------|---------|---------|----------|-------------|-----------------|----------|
| **Pandas** | latest | PadChest CSV parsing, label extraction, difficulty scoring | Same | None (CPU) | 160K-row CSV with nested list columns | üî¥ MUST |
| **Pillow** | ‚â•10.0 | X-ray image loading, resizing, format conversion | Same | None (CPU) | MedGemma requires PIL image input | üî¥ MUST |
| **Albumentations** | latest | CXR-specific augmentation: rotation, brightness, contrast | NEW | None (CPU) | Medical image augmentation best practices | üü° SHOULD |
| **HuggingFace Datasets** | latest | Streaming dataset support, memory-mapped loading | NEW | None (CPU) | Efficient handling of 160K+ image dataset | üü° SHOULD |
| **Scikit-learn** | latest | Train/val/test splitting, stratification, evaluation metrics | Same | None (CPU) | Per-finding P/R/F1 calculation | üî¥ MUST |

#### üèãÔ∏è 5. Training & Tracking

| Tool | Version | Purpose | Replaces | VRAM Impact | Research Backing | Priority |
|------|---------|---------|----------|-------------|-----------------|----------|
| **Weights & Biases** | latest | Experiment tracking, hyperparameter sweeps, model registry | TensorBoard (v2) | None | Industry standard for ML experiment tracking | üü° SHOULD |
| **TensorBoard** | latest | Training curve visualization (fallback, already integrated) | Same (v2) | None | Built into TRL report_to config | üî¥ MUST |
| **Optuna** | latest | Hyperparameter optimization (LoRA rank, LR, warmup) | NEW | None (CPU) | Bayesian optimization for fine-tuning hyperparams | üü¢ NICE |

#### üéØ 6. Evaluation

| Tool | Version | Purpose | Replaces | VRAM Impact | Research Backing | Priority |
|------|---------|---------|----------|-------------|-----------------|----------|
| **RadGraph** ‚≠ê | latest | RadGraph F1 metric ‚Äî industry standard for report quality | NEW | ~1 GB (inference) | arXiv:2106.14463 | üî¥ MUST |
| **CheXbert** | latest | Extract 14 CheXpert labels from generated reports | NEW | <1 GB (inference) | Stanford CheXbert for automated report labeling | üü° SHOULD |
| **f1chexbert** | latest | Compute CheXbert F1 from report pairs | NEW | None (uses CheXbert) | Standardized metric computation | üü° SHOULD |

#### üìç 7. Localization

| Tool | Version | Purpose | Replaces | VRAM Impact | Research Backing | Priority |
|------|---------|---------|----------|-------------|-----------------|----------|
| **MedSAM** ‚≠ê | latest | Pixel-accurate CXR segmentation from bounding box prompts | Manual 26-region bbox (v2) | <1 GB | arXiv:2304.12306 | üî¥ MUST |
| **OpenCV** | latest | Image processing for overlay rendering, contour extraction | NEW | None (CPU) | Standard CV library | üü° SHOULD |
| **Matplotlib** | latest | Visualization: side-by-side X-ray panels, colorbar, legend | Same (v2) | None (CPU) | Already used in v2 visualization | üî¥ MUST |

#### üé® 8. Visualization

| Tool | Version | Purpose | Replaces | VRAM Impact | Research Backing | Priority |
|------|---------|---------|----------|-------------|-----------------|----------|
| **Matplotlib** | latest | Static plots: training curves, X-ray overlays, per-finding charts | Same (v2) | None | Already integrated | üî¥ MUST |
| **Plotly** | latest | Interactive dashboard for model performance analysis | NEW | None | Interactive exploration of 174-finding results | üü° SHOULD |
| **Gradio** ‚≠ê | latest | Web UI for interactive X-ray analysis demo | NEW | None (CPU except model) | Industry standard for ML demos; many MedGemma Spaces use it | üü° SHOULD |

#### üöÄ 9. Serving / API

| Tool | Version | Purpose | Replaces | VRAM Impact | Research Backing | Priority |
|------|---------|---------|----------|-------------|-----------------|----------|
| **FastAPI** ‚≠ê | latest | REST API for X-ray analysis (production serving) | None (v2 has no API) | None (CPU) | Industry standard async Python API framework | üü° SHOULD |
| **Uvicorn** | latest | ASGI server for FastAPI | NEW | None | Production-grade async server | üü° SHOULD |
| **vLLM** | ‚â•0.12 | High-throughput LLM inference serving with continuous batching | NEW | Same model VRAM | TRL v0.27.0 integration | üü¢ NICE |

#### üê≥ 10. DevOps

| Tool | Version | Purpose | Replaces | VRAM Impact | Research Backing | Priority |
|------|---------|---------|----------|-------------|-----------------|----------|
| **Docker** | latest | Containerized training and serving environments | NEW | None | Reproducible environments | üü° SHOULD |
| **pre-commit** | latest | Git hooks for linting, formatting on every commit | NEW | None | Code quality automation | üü° SHOULD |
| **Ruff** | latest | Fast Python linter and formatter (replaces flake8 + isort) | NEW | None | 100x faster than flake8 | üü° SHOULD |

#### üìà 11. Monitoring

| Tool | Version | Purpose | Replaces | VRAM Impact | Research Backing | Priority |
|------|---------|---------|----------|-------------|-----------------|----------|
| **Weights & Biases Alerts** | latest | Automated alerts when model accuracy drops below threshold | NEW | None | W&B monitoring features | üü¢ NICE |
| **Great Expectations** | latest | Data quality monitoring and validation | NEW | None (CPU) | Data drift detection for medical data | üü¢ NICE |

#### üß™ 12. Testing

| Tool | Version | Purpose | Replaces | VRAM Impact | Research Backing | Priority |
|------|---------|---------|----------|-------------|-----------------|----------|
| **pytest** | latest | Unit tests, integration tests, model tests | NEW | None | Python testing standard | üü° SHOULD |
| **pytest-cov** | latest | Code coverage reporting | NEW | None | Quality assurance | üü° SHOULD |

---

#### v2 ‚Üí v3 Stack Diff Summary

| Layer | v2 (Current) | v3 (Recommended) | Why Change |
|-------|-------------|------------------|-----------|
| **Model** | `google/medgemma-4b-it` v1.0.1 | `google/medgemma-1.5-4b-it` v1.5.0 ‚≠ê | Native bounding box (IoU 3.1‚Üí38.0), longitudinal CXR, +0.6% MIMIC F1, same VRAM |
| **Transformers** | ‚â•4.52.0 | ‚â•5.1.0 | Required for MedGemma 1.5, weekly updates, dynamic weight loading |
| **TRL** | ‚â•0.17.0 | ‚â•0.27.2 | `forward_masked_logits` saves 50% VRAM, GDPO/CISPO loss, v5 compat |
| **PEFT** | ‚â•0.15.0 | ‚â•0.18.1 | DoRA/DeLoRA options, `ensure_weight_tying`, v5 compat |
| **PEFT Method** | LoRA (r=32, Œ±=64) | DoRA (r=32, Œ±=64) | DoRA consistently outperforms LoRA at same VRAM cost |
| **Localization** | Text ‚Üí 26 manual bbox regions | MedGemma 1.5 native bbox + MedSAM masks | Model-predicted bbox ‚Üí pixel-accurate masks |
| **Evaluation** | Soft match accuracy only | + RadGraph F1 + CheXbert F1 + per-finding | Industry-standard metrics required for credibility |
| **Experiment Tracking** | TensorBoard only | + W&B | Better sweeps, model registry, team collaboration |
| **API** | None | FastAPI + Gradio | Production deployment and demo interface |
| **Testing** | None | pytest suite | Reliability and CI/CD |
| **Linting** | None | Ruff + pre-commit | Code quality automation |
| **Containerization** | None | Docker | Reproducible environments |

---

### B3. Architecture Visualization JSON (v3)

The complete v3 architecture visualization prompt is saved as a separate file:

**üìÑ `architecture_prompt_v3.json`** ‚Äî 1000+ lines, valid JSON, following the exact schema of the existing `architecture_prompt.json`.

Key changes from v2 JSON:
- Version updated to **3.0**
- Section 2 updated: MedGemma 1.5 4B-it with native bounding box specs
- Section 1 updated: Library versions bumped (Transformers ‚â•5.1.0, TRL ‚â•0.27.2, PEFT ‚â•0.18.1)
- **5 new sections added:**
  - Section 12: "Auxiliary Models & Ensemble Pipeline" (MedSAM, BiomedCLIP, CheXbert, RadGraph, CheXagent)
  - Section 13: "Advanced Localization (MedGemma 1.5 Native + MedSAM)"
  - Section 14: "API & Deployment Architecture" (FastAPI, Gradio, Docker, vLLM)
  - Section 15: "Monitoring & Experiment Tracking" (W&B, drift detection, alerts)
  - Section 16: "Research-Backed Improvements Log" (forward_masked_logits, DoRA, RadGraph F1)
- Updated `architectureDiagram` flow with new stages
- Updated `quickReference` for v3
- New `v2vsV3` comparison table
- All colors, gradients, icons consistent with v2 theme

---

## Part C: Action Plan

---

### C1. Quick Wins (This Week, <8 hours each)

| # | Action | Expected Impact | Effort | Dependencies |
|---|--------|----------------|--------|-------------|
| 1 | **Upgrade model to MedGemma 1.5 4B-it** | +0.6% MIMIC CXR F1, native bounding box localization (IoU 3.1‚Üí38.0), longitudinal CXR support | 2 hours | Change `model_id` in notebook Cell 5, accept HF license for new model |
| 2 | **Enable forward_masked_logits in TRL** | ~50% VRAM reduction during forward pass ‚Üí can increase batch size to 2 or LoRA rank to 64 | 1 hour | `pip install trl>=0.27.2`, add `forward_masked_logits=True` to SFTConfig |
| 3 | **Switch LoRA to DoRA** | +1-3% accuracy with zero VRAM increase | 30 min | `pip install peft>=0.18.1`, add `use_dora=True` to LoraConfig |
| 4 | **Upgrade Transformers to v5.1.0** | Required for MedGemma 1.5, better performance, weekly updates | 2 hours | `pip install transformers>=5.1.0`, verify PyTorch ‚â•2.4, test notebook end-to-end |
| 5 | **Add ensure_weight_tying=True to LoRA** | Proper weight tying for lm_head + embed_tokens (modules_to_save) | 15 min | PEFT ‚â•0.18.0, add `ensure_weight_tying=True` to LoraConfig |
| 6 | **Extract native bounding boxes from MedGemma 1.5 output** | Replace manual 26-region mapping with model-predicted bbox coordinates | 4 hours | MedGemma 1.5 loaded, parse bounding box tokens from generated text |

---

### C2. Medium Term (Next 2‚Äì4 Weeks)

| # | Action | Expected Impact | Effort | Dependencies |
|---|--------|----------------|--------|-------------|
| 1 | **Add RadGraph F1 evaluation metric** | Industry-standard report quality metric alongside soft match accuracy | 3 days | Install radgraph package, write evaluation pipeline, validate on test set |
| 2 | **Integrate MedSAM for pixel-accurate localization** | Replace crude bounding boxes with precise anatomical segmentation masks | 5 days | Download MedSAM weights (~93M, <1 GB VRAM), build prompt pipeline: MedGemma bbox ‚Üí MedSAM mask |
| 3 | **Build FastAPI serving endpoint** | Production-ready API: POST /predict with X-ray image ‚Üí structured report + visualization | 3 days | FastAPI, Uvicorn, model loading with 4-bit inference |
| 4 | **Build Gradio interactive demo** | Web UI for interactive X-ray analysis with image upload and visualization | 2 days | Gradio, model inference pipeline, overlay rendering |
| 5 | **Add pytest test suite** | Automated testing for data pipeline, metrics, report parsing, API routes | 3 days | pytest, sample test data, mock model for CI |
| 6 | **Set up W&B experiment tracking** | Better hyperparameter logging, model comparison, sweep dashboards | 1 day | W&B account, add to training config, log metrics |
| 7 | **Implement CheXbert evaluation** | Extract 14 CheXpert labels from generated reports for standardized comparison | 2 days | CheXbert model, label extraction pipeline, F1 computation |

---

### C3. Long Term (Next 2‚Äì3 Months)

| # | Action | Expected Impact | Effort | Dependencies |
|---|--------|----------------|--------|-------------|
| 1 | **CheXagent ensemble pipeline** | +2-5% accuracy on complex multi-finding cases via confidence voting between MedGemma 1.5 + CheXagent-2-3b | 2 weeks | Both models loaded (total ~4 GB at 4-bit), ensemble logic, confidence calibration |
| 2 | **RAG with radiology knowledge base** | +3-5% on rare findings by retrieving relevant textbook passages during inference | 2 weeks | BiomedCLIP embeddings, vector DB (ChromaDB/FAISS), retrieval pipeline |
| 3 | **Hyperparameter optimization with Optuna** | Find optimal LoRA rank, LR, warmup for MedGemma 1.5 + DoRA combination | 1 week | Optuna, define search space, run 20-50 trials |
| 4 | **Docker containerization** | Reproducible training and serving environments | 1 week | Dockerfile.train, Dockerfile.serve, docker-compose.yml |
| 5 | **VinDr-CXR localization evaluation** | Validate localization accuracy against radiologist bounding box annotations | 1 week | VinDr-CXR dataset access (PhysioNet), IoU evaluation pipeline |
| 6 | **Longitudinal CXR comparison feature** | Compare current vs prior X-rays to track disease progression (MedGemma 1.5 native capability) | 2 weeks | MS-CXR-T dataset, multi-image input pipeline, temporal analysis |
| 7 | **Synthetic CXR augmentation for rare findings** | Generate synthetic X-rays for underrepresented findings to balance training data | 3 weeks | Medical diffusion model (offline generation), quality filtering |

---

### C4. Research Watchlist (Monitor for Updates)

| # | Topic | Why We're Watching | Check Frequency | Source to Monitor |
|---|-------|-------------------|-----------------|------------------|
| 1 | **MedGemma 2.0 / next release** | Could bring further accuracy improvements, new capabilities, improved fine-tuning recipes | Weekly | https://huggingface.co/google?search=medgemma |
| 2 | **Transformers v5.x weekly releases** | May break or improve our pipeline; new model architectures | Weekly | https://github.com/huggingface/transformers/releases |
| 3 | **PEFT new methods (v0.19+)** | New PEFT methods may outperform DoRA; MiSS replacing Bone shows rapid evolution | Monthly | https://github.com/huggingface/peft/releases |
| 4 | **TRL forward_masked_logits improvements** | VRAM savings may increase beyond 50%; new loss functions (GDPO, CISPO) | Monthly | https://github.com/huggingface/trl/releases |
| 5 | **MedSAM 2 / SAM 3** | Next-gen medical segmentation with improved accuracy and efficiency | Monthly | https://huggingface.co/models?search=medsam |
| 6 | **CheXagent updates** | Stanford AIMI actively updating; srrg-findings and srrg-impression variants | Monthly | https://huggingface.co/StanfordAIMI |
| 7 | **FDA/CE AI radiology approvals** | Regulatory landscape affects deployment strategy and clinical validation requirements | Quarterly | FDA AI/ML SaMD, EU MDR updates |
| 8 | **Medical VLM benchmarks** | New benchmarks (MedXpertQA, AfriMed-QA) provide evaluation opportunities | Monthly | arXiv medical AI, PhysioNet new datasets |
| 9 | **vLLM medical model serving** | When vLLM adds MedGemma/Gemma 3 support, enables high-throughput serving | Monthly | https://github.com/vllm-project/vllm |
| 10 | **Phi-4 medical fine-tunes** | If community creates medical Phi-4 fine-tunes, could be strong 12 GB alternative | Monthly | https://huggingface.co/models?search=phi-4+medical |

---

## Appendix: Key MedGemma 1.5 vs 1.0 Benchmark Comparison

This data was extracted from the official MedGemma 1.5 model card on HuggingFace (verified Feb 10, 2026).

| Benchmark | Metric | Gemma 3 4B (baseline) | MedGemma 1.0 4B | MedGemma 1.5 4B | MedGemma 1.0 27B |
|-----------|--------|----------------------|-----------------|-----------------|-----------------|
| **MIMIC CXR** | Macro F1 (top 5) | 81.2 | 88.9 | **89.5** | 90.0 |
| **CheXpert** | Macro F1 (top 5) | 32.6 | 48.1 | **48.2** | 49.9 |
| **CXR14** | Macro F1 (3 cond.) | 32.0 | 50.1 | **48.4** | 45.3 |
| **Chest ImaGenome** ‚≠ê | IoU (bbox) | 5.7 | 3.1 | **38.0** | 16.0 |
| **MS-CXR-T** (longitudinal) | Macro Accuracy | 59.0 | 61.1 | **65.7** | 50.1 |
| **SLAKE** (VQA) | Tokenized F1 | 40.2 | 72.3 | 59.7 | 70.3 |
| **MedQA** (text) | 4-option accuracy | 50.7 | 64.4 | **69.1** | 85.3 |
| **EHRQA** (records) | Accuracy | 70.9 | 67.6 | **89.6** | 90.5 |

**Key takeaway for v3:** MedGemma 1.5's bounding box localization improved **12√ó (IoU 3.1‚Üí38.0)** ‚Äî this single upgrade transforms our localization capability from toy-level to clinically meaningful. Combined with +0.6% CXR F1 and +4.7% MedQA improvement, upgrading is a no-brainer.

---

*End of Deep Research Report. See `architecture_prompt_v3.json` for the complete v3 architecture visualization JSON (1000+ lines).*
