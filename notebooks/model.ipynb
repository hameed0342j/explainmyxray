{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ec4eb00",
   "metadata": {},
   "source": [
    "# ü©ª ExplainMyXray - Advanced MedGemma Training\n",
    "\n",
    "## Features:\n",
    "- **Large-Scale Datasets**: NIH ChestX-ray14 (112K), CheXpert (224K), MIMIC-CXR (377K), PadChest (160K)\n",
    "- **Gemma 3 Architecture**: PaliGemma2 with 4-bit QLoRA fine-tuning\n",
    "- **Advanced Training**: 15+ epochs, cosine LR scheduler, early stopping, gradient clipping\n",
    "- **Comprehensive Evaluation**: BLEU, ROUGE, BERTScore, clinical accuracy metrics\n",
    "- **Proper Data Splits**: Train (80%) / Validation (10%) / Test (10%)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f7f6097",
   "metadata": {},
   "source": [
    "## üì¶ Cell 1: Install Dependencies\n",
    "\n",
    "**‚ö†Ô∏è IMPORTANT WORKFLOW:**\n",
    "1. Run Cell 1 (Install) ‚Üí Wait for completion\n",
    "2. Click \"RESTART SESSION\" button that appears  \n",
    "3. Skip Cell 1, run Cell 1b (Verify) onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8acee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COLAB T4 OPTIMIZED - Install Dependencies (Jan 2026)\n",
    "# ============================================================\n",
    "# IMPORTANT: \n",
    "# 1. Run this cell FIRST\n",
    "# 2. When it completes, click \"RESTART SESSION\" button that appears\n",
    "# 3. Then run Cell 2 onwards (skip re-running this cell)\n",
    "\n",
    "import os\n",
    "\n",
    "# ============================================================\n",
    "# STEP 1: Uninstall conflicting pre-installed packages\n",
    "# ============================================================\n",
    "print(\"üßπ Cleaning up conflicting packages...\")\n",
    "!pip uninstall -y transformers peft accelerate bitsandbytes -q 2>/dev/null || true\n",
    "\n",
    "# ============================================================\n",
    "# STEP 2: Install compatible versions (numpy 2.x compatible)\n",
    "# ============================================================\n",
    "print(\"\\nüì¶ Installing ML libraries...\")\n",
    "\n",
    "# Core ML libraries - use versions compatible with Colab's numpy 2.x\n",
    "!pip install -q --upgrade pip setuptools wheel\n",
    "\n",
    "# Install transformers and related packages (numpy 2.x compatible)\n",
    "!pip install -q \"transformers>=4.47.0\"\n",
    "!pip install -q \"peft>=0.14.0\"\n",
    "!pip install -q \"accelerate>=1.0.0\"\n",
    "!pip install -q \"bitsandbytes>=0.45.0\"\n",
    "!pip install -q \"datasets>=3.0.0\"\n",
    "\n",
    "# Data & visualization (don't constrain numpy - use Colab's version)\n",
    "!pip install -q \"pillow>=10.0.0\" scikit-learn matplotlib seaborn\n",
    "\n",
    "# Evaluation metrics\n",
    "!pip install -q evaluate sacrebleu rouge_score nltk\n",
    "\n",
    "# Dataset download utilities  \n",
    "!pip install -q kaggle gdown opendatasets tqdm\n",
    "\n",
    "# Fix jedi for IPython (optional warning fix)\n",
    "!pip install -q jedi\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ INSTALLATION COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\")\n",
    "print(\"‚ö†Ô∏è  IMPORTANT: You MUST restart the runtime now!\")\n",
    "print(\"\")\n",
    "print(\"   Click: Runtime ‚Üí Restart session\")\n",
    "print(\"   OR click the 'RESTART SESSION' button above\")\n",
    "print(\"\")\n",
    "print(\"   After restart, skip this cell and run Cell 2 onwards.\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649e8752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 1b: VERIFY INSTALLATION (Run after restart)\n",
    "# ============================================================\n",
    "# Run this cell AFTER restarting the runtime\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import peft\n",
    "import accelerate\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"üîß SYSTEM INFO - COLAB T4\")\n",
    "print(\"=\"*60)\n",
    "print(f\"PyTorch:       {torch.__version__}\")\n",
    "print(f\"Transformers:  {transformers.__version__}\")\n",
    "print(f\"PEFT:          {peft.__version__}\")\n",
    "print(f\"Accelerate:    {accelerate.__version__}\")\n",
    "print(f\"NumPy:         {np.__version__}\")\n",
    "\n",
    "print(f\"\\nCUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU:           {torch.cuda.get_device_name(0)}\")\n",
    "    gpu_mem = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
    "    print(f\"VRAM:          {gpu_mem:.1f} GB\")\n",
    "    if \"T4\" in torch.cuda.get_device_name(0):\n",
    "        print(\"‚úÖ T4 GPU detected - config optimized for 16GB VRAM\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è  Non-T4 GPU detected - may need batch_size adjustment\")\n",
    "\n",
    "# Check bitsandbytes\n",
    "try:\n",
    "    import bitsandbytes as bnb\n",
    "    print(f\"Bitsandbytes:  {bnb.__version__}\")\n",
    "    print(\"‚úÖ All imports successful!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Bitsandbytes issue: {e}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53619057",
   "metadata": {},
   "source": [
    "## üîê Cell 2: Authentication (Hugging Face + Kaggle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043082cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Cell 6: HUGGING FACE + KAGGLE AUTHENTICATION\n",
    "# ============================================================\n",
    "\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# ============================================================\n",
    "# HUGGING FACE LOGIN\n",
    "# ============================================================\n",
    "HF_TOKEN = \"REDACTED_TOKEN_USE_ENV_VAR\"\n",
    "login(token=HF_TOKEN)\n",
    "print(\"‚úÖ Logged in to Hugging Face!\")\n",
    "\n",
    "# ============================================================\n",
    "# KAGGLE AUTHENTICATION - Multiple fallback methods\n",
    "# ============================================================\n",
    "kaggle_ready = False\n",
    "\n",
    "# Method 1: Check if kaggle.json exists in /content/ (uploaded file)\n",
    "content_kaggle = Path(\"/content/kaggle.json\")\n",
    "if content_kaggle.exists():\n",
    "    # Copy to ~/.kaggle/\n",
    "    kaggle_dir = Path.home() / \".kaggle\"\n",
    "    kaggle_dir.mkdir(exist_ok=True)\n",
    "    shutil.copy(content_kaggle, kaggle_dir / \"kaggle.json\")\n",
    "    os.chmod(kaggle_dir / \"kaggle.json\", 0o600)\n",
    "    print(\"‚úÖ Kaggle credentials copied from /content/kaggle.json to ~/.kaggle/\")\n",
    "    kaggle_ready = True\n",
    "\n",
    "# Method 2: Check ~/.kaggle/kaggle.json\n",
    "if not kaggle_ready:\n",
    "    kaggle_path = Path.home() / \".kaggle\" / \"kaggle.json\"\n",
    "    if kaggle_path.exists():\n",
    "        print(\"‚úÖ Kaggle credentials found in ~/.kaggle/kaggle.json\")\n",
    "        kaggle_ready = True\n",
    "\n",
    "# Method 3: Try Colab secrets\n",
    "if not kaggle_ready:\n",
    "    try:\n",
    "        from google.colab import userdata\n",
    "        username = userdata.get('KAGGLE_USERNAME')\n",
    "        key = userdata.get('KAGGLE_KEY')\n",
    "        if username and key:\n",
    "            os.environ['KAGGLE_USERNAME'] = username\n",
    "            os.environ['KAGGLE_KEY'] = key\n",
    "            print(\"‚úÖ Kaggle credentials loaded from Colab secrets!\")\n",
    "            kaggle_ready = True\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Method 4: Check environment variables\n",
    "if not kaggle_ready:\n",
    "    if os.environ.get('KAGGLE_USERNAME') and os.environ.get('KAGGLE_KEY'):\n",
    "        print(\"‚úÖ Kaggle credentials found in environment variables!\")\n",
    "        kaggle_ready = True\n",
    "\n",
    "if not kaggle_ready:\n",
    "    print(\"‚ö†Ô∏è Kaggle credentials not found!\")\n",
    "    print(\"   Please upload kaggle.json to /content/ or set Colab secrets\")\n",
    "\n",
    "print(\"\\n‚úÖ Authentication complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8dd37c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class ChestXrayDataset(Dataset):\n",
    "    \"\"\"Dataset for chest X-ray training with augmentation - PaliGemma optimized\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        processor,\n",
    "        max_length: int = 384,\n",
    "        is_train: bool = True,\n",
    "    ):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.processor = processor\n",
    "        self.max_length = max_length\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Medical-appropriate augmentation for training\n",
    "        if is_train:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(p=0.3),\n",
    "                transforms.RandomRotation(degrees=5),\n",
    "                transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = None\n",
    "        \n",
    "        # Cache failed image paths to avoid repeated errors\n",
    "        self.failed_images = set()\n",
    "        \n",
    "        print(f\"{'Train' if is_train else 'Eval'} dataset: {len(self.df)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load image with caching of failures\n",
    "        img_path = row[\"ImagePath\"]\n",
    "        try:\n",
    "            if img_path not in self.failed_images:\n",
    "                image = Image.open(img_path).convert(\"RGB\")\n",
    "            else:\n",
    "                image = Image.new(\"RGB\", (224, 224), color=(128, 128, 128))\n",
    "        except Exception as e:\n",
    "            self.failed_images.add(img_path)\n",
    "            image = Image.new(\"RGB\", (224, 224), color=(128, 128, 128))\n",
    "        \n",
    "        # Apply augmentation\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get report text\n",
    "        text = str(row.get(\"Report\", \"\")).strip()\n",
    "        if not text or text == \"nan\":\n",
    "            text = \"Normal chest radiograph.\"\n",
    "        \n",
    "        # Create varied prompts for better generalization\n",
    "        # Note: PaliGemma processor automatically handles <image> token when images are passed\n",
    "        prompts = [\n",
    "            \"describe this chest xray\",\n",
    "            \"explain this chest radiograph\", \n",
    "            \"analyze this xray image\",\n",
    "            \"what does this chest xray show\",\n",
    "            \"interpret this chest radiograph\",\n",
    "        ]\n",
    "        prompt = random.choice(prompts) if self.is_train else \"describe this chest xray\"\n",
    "        \n",
    "        # Process with PaliGemma processor\n",
    "        # The processor handles image token insertion automatically\n",
    "        try:\n",
    "            inputs = self.processor(\n",
    "                text=prompt,\n",
    "                images=image,\n",
    "                suffix=text,  # This is the target output (report)\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Fallback without suffix parameter\n",
    "            full_text = f\"{prompt}: {text}\"\n",
    "            inputs = self.processor(\n",
    "                text=full_text,\n",
    "                images=image,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "            )\n",
    "        \n",
    "        return {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "\n",
    "print(\"‚úÖ ChestXrayDataset class defined (optimized for PaliGemma)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efd8fab",
   "metadata": {},
   "source": [
    "## üìä Cell 3: Download Kaggle Datasets (AUTOMATIC)\n",
    "\n",
    "### Datasets Used:\n",
    "1. **Chest X-Ray Pneumonia** (~5,863 images) - `paultimothymooney/chest-xray-pneumonia`\n",
    "2. **NIH Chest X-ray Sample** (~5,606 images) - `nih-chest-xrays/sample`\n",
    "3. **COVID-19 Radiography** (~21,165 images) - `tawsifurrahman/covid19-radiography-database`\n",
    "\n",
    "**No manual upload required!** Just run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f5bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# ============================================================\n",
    "# GOOGLE DRIVE SETUP - PERSISTENT STORAGE\n",
    "# ============================================================\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Store datasets in Google Drive (persists across sessions!)\n",
    "DRIVE_DATA_ROOT = Path(\"/content/drive/MyDrive/ExplainMyXray_Datasets\")\n",
    "DRIVE_DATA_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Local cache for faster training\n",
    "DATA_ROOT = Path(\"/content/datasets\")\n",
    "DATA_ROOT.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Drive storage: {DRIVE_DATA_ROOT}\")\n",
    "print(f\"üìÅ Local cache: {DATA_ROOT}\")\n",
    "\n",
    "# Define directories\n",
    "PNEUMONIA_DIR = DATA_ROOT / \"chest_xray_pneumonia\"\n",
    "NIH_SAMPLE_DIR = DATA_ROOT / \"nih_sample\"\n",
    "\n",
    "drive_pneumonia = DRIVE_DATA_ROOT / \"chest_xray_pneumonia\"\n",
    "drive_nih = DRIVE_DATA_ROOT / \"nih_sample\"\n",
    "\n",
    "# ============================================================\n",
    "# CHECK IF DATA ALREADY EXISTS IN DRIVE\n",
    "# ============================================================\n",
    "pneumonia_cached = drive_pneumonia.exists() and any(drive_pneumonia.rglob(\"*.jpeg\"))\n",
    "nih_cached = drive_nih.exists() and any(drive_nih.rglob(\"*.png\"))\n",
    "\n",
    "need_kaggle = not (pneumonia_cached and nih_cached)\n",
    "\n",
    "if pneumonia_cached and nih_cached:\n",
    "    print(\"\\n‚úÖ Both datasets found in Google Drive! Loading from cache...\")\n",
    "    print(\"   (No Kaggle credentials needed)\")\n",
    "    kaggle_configured = True\n",
    "    \n",
    "    # Copy from Drive to local\n",
    "    if not PNEUMONIA_DIR.exists():\n",
    "        print(f\"   üìÇ Loading chest_xray_pneumonia...\")\n",
    "        shutil.copytree(drive_pneumonia, PNEUMONIA_DIR)\n",
    "    \n",
    "    if not NIH_SAMPLE_DIR.exists():\n",
    "        print(f\"   üìÇ Loading nih_sample...\")\n",
    "        shutil.copytree(drive_nih, NIH_SAMPLE_DIR)\n",
    "\n",
    "else:\n",
    "    # ============================================================\n",
    "    # KAGGLE API SETUP (only if data not fully cached)\n",
    "    # ============================================================\n",
    "    print(\"\\nüîê Setting up Kaggle API...\")\n",
    "    \n",
    "    KAGGLE_USERNAME = \"\"  # ‚Üê Enter your Kaggle username here\n",
    "    KAGGLE_KEY = \"\"       # ‚Üê Enter your Kaggle API key here\n",
    "    \n",
    "    kaggle_configured = False\n",
    "    \n",
    "    if KAGGLE_USERNAME and KAGGLE_KEY:\n",
    "        kaggle_dir = Path.home() / \".kaggle\"\n",
    "        kaggle_dir.mkdir(exist_ok=True)\n",
    "        kaggle_json = kaggle_dir / \"kaggle.json\"\n",
    "        \n",
    "        with open(kaggle_json, \"w\") as f:\n",
    "            json.dump({\"username\": KAGGLE_USERNAME, \"key\": KAGGLE_KEY}, f)\n",
    "        os.chmod(kaggle_json, 0o600)\n",
    "        print(\"‚úÖ Kaggle configured with direct credentials!\")\n",
    "        kaggle_configured = True\n",
    "    else:\n",
    "        from google.colab import files\n",
    "        kaggle_dir = Path.home() / \".kaggle\"\n",
    "        kaggle_dir.mkdir(exist_ok=True)\n",
    "        kaggle_json = kaggle_dir / \"kaggle.json\"\n",
    "        \n",
    "        if not kaggle_json.exists():\n",
    "            print(\"üì§ Upload your kaggle.json file:\")\n",
    "            try:\n",
    "                uploaded = files.upload()\n",
    "                if uploaded:\n",
    "                    filename = list(uploaded.keys())[0]\n",
    "                    with open(kaggle_json, \"wb\") as f:\n",
    "                        f.write(uploaded[filename])\n",
    "                    os.chmod(kaggle_json, 0o600)\n",
    "                    print(\"‚úÖ Kaggle API configured!\")\n",
    "                    kaggle_configured = True\n",
    "            except:\n",
    "                print(\"‚ö†Ô∏è kaggle.json not uploaded\")\n",
    "        else:\n",
    "            print(\"‚úÖ Kaggle already configured!\")\n",
    "            kaggle_configured = True\n",
    "    \n",
    "    # ============================================================\n",
    "    # DOWNLOAD DATASETS\n",
    "    # ============================================================\n",
    "    if kaggle_configured:\n",
    "        \n",
    "        # DATASET 1: Chest X-Ray Pneumonia\n",
    "        print(\"\\nüì• Dataset 1: Chest X-Ray Pneumonia\")\n",
    "        if pneumonia_cached:\n",
    "            print(\"   ‚úÖ Found in Drive cache, copying to local...\")\n",
    "            if not PNEUMONIA_DIR.exists():\n",
    "                shutil.copytree(drive_pneumonia, PNEUMONIA_DIR)\n",
    "        else:\n",
    "            print(\"   üì• Downloading from Kaggle...\")\n",
    "            !kaggle datasets download -d paultimothymooney/chest-xray-pneumonia -p {DATA_ROOT} --unzip -q\n",
    "            # Rename extracted folder\n",
    "            if (DATA_ROOT / \"chest_xray\").exists():\n",
    "                if PNEUMONIA_DIR.exists():\n",
    "                    shutil.rmtree(PNEUMONIA_DIR)\n",
    "                shutil.move(str(DATA_ROOT / \"chest_xray\"), str(PNEUMONIA_DIR))\n",
    "            # Cache to Drive\n",
    "            if PNEUMONIA_DIR.exists():\n",
    "                print(\"   üíæ Caching to Drive...\")\n",
    "                if drive_pneumonia.exists():\n",
    "                    shutil.rmtree(drive_pneumonia)\n",
    "                shutil.copytree(PNEUMONIA_DIR, drive_pneumonia)\n",
    "        \n",
    "        pneumonia_count = sum(1 for _ in PNEUMONIA_DIR.rglob(\"*.jpeg\")) if PNEUMONIA_DIR.exists() else 0\n",
    "        print(f\"   ‚úÖ Chest X-Ray Pneumonia: {pneumonia_count:,} images\")\n",
    "\n",
    "        # DATASET 2: NIH Chest X-ray Sample  \n",
    "        # Download DIRECTLY into nih_sample folder (like original code)\n",
    "        print(\"\\nüì• Dataset 2: NIH Chest X-ray Sample\")\n",
    "        if nih_cached:\n",
    "            print(\"   ‚úÖ Found in Drive cache, copying to local...\")\n",
    "            if not NIH_SAMPLE_DIR.exists():\n",
    "                shutil.copytree(drive_nih, NIH_SAMPLE_DIR)\n",
    "        else:\n",
    "            print(\"   üì• Downloading from Kaggle...\")\n",
    "            # Download directly into nih_sample folder (this is what worked before!)\n",
    "            NIH_SAMPLE_DIR.mkdir(exist_ok=True)\n",
    "            !kaggle datasets download -d nih-chest-xrays/sample -p {NIH_SAMPLE_DIR} --unzip -q\n",
    "            \n",
    "            # Cache to Drive\n",
    "            if NIH_SAMPLE_DIR.exists() and any(NIH_SAMPLE_DIR.rglob(\"*.png\")):\n",
    "                print(\"   üíæ Caching to Drive...\")\n",
    "                if drive_nih.exists():\n",
    "                    shutil.rmtree(drive_nih)\n",
    "                shutil.copytree(NIH_SAMPLE_DIR, drive_nih)\n",
    "\n",
    "# ============================================================\n",
    "# VERIFY NIH DATASET STRUCTURE\n",
    "# ============================================================\n",
    "nih_csv = None\n",
    "nih_images = None\n",
    "\n",
    "if NIH_SAMPLE_DIR.exists():\n",
    "    # Search for sample_labels.csv\n",
    "    for csv_path in NIH_SAMPLE_DIR.rglob(\"sample_labels.csv\"):\n",
    "        nih_csv = csv_path\n",
    "        break\n",
    "    \n",
    "    # Search for images directory\n",
    "    for img_dir in NIH_SAMPLE_DIR.rglob(\"images\"):\n",
    "        if img_dir.is_dir() and any(img_dir.glob(\"*.png\")):\n",
    "            nih_images = img_dir\n",
    "            break\n",
    "\n",
    "# ============================================================\n",
    "# SUMMARY\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä DATASET SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Pneumonia\n",
    "pneumonia_count = sum(1 for _ in PNEUMONIA_DIR.rglob(\"*.jpeg\")) if PNEUMONIA_DIR.exists() else 0\n",
    "if pneumonia_count > 0:\n",
    "    print(f\"   ‚úÖ Chest X-Ray Pneumonia: {pneumonia_count:,} images\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è Chest X-Ray Pneumonia: not found\")\n",
    "\n",
    "# NIH\n",
    "nih_count = sum(1 for _ in NIH_SAMPLE_DIR.rglob(\"*.png\")) if NIH_SAMPLE_DIR.exists() else 0\n",
    "if nih_count > 0:\n",
    "    print(f\"   ‚úÖ NIH Chest X-ray Sample: {nih_count:,} images\")\n",
    "    if nih_csv:\n",
    "        df_nih_temp = pd.read_csv(nih_csv)\n",
    "        print(f\"      Labels CSV found: {len(df_nih_temp):,} entries\")\n",
    "    else:\n",
    "        print(f\"      ‚ö†Ô∏è Labels CSV not found\")\n",
    "        # Debug\n",
    "        print(f\"      Directory contents:\")\n",
    "        for item in list(NIH_SAMPLE_DIR.iterdir())[:5]:\n",
    "            print(f\"         - {item.name}\")\n",
    "else:\n",
    "    print(f\"   ‚ö†Ô∏è NIH Chest X-ray Sample: not found\")\n",
    "    if NIH_SAMPLE_DIR.exists():\n",
    "        print(f\"      Directory contents:\")\n",
    "        for item in list(NIH_SAMPLE_DIR.iterdir())[:5]:\n",
    "            print(f\"         - {item.name}\")\n",
    "\n",
    "total_images = pneumonia_count + nih_count\n",
    "if total_images == 0:\n",
    "    print(\"\\n‚ö†Ô∏è No datasets downloaded!\")\n",
    "    print(\"   Please enter your Kaggle credentials above and re-run this cell.\")\n",
    "else:\n",
    "    print(f\"\\n   TOTAL: {total_images:,} images available!\")\n",
    "    print(f\"\\nüíæ Data location: {DRIVE_DATA_ROOT}\")\n",
    "    print(f\"   Next time, data loads from Drive (no re-download)\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3456a910",
   "metadata": {},
   "source": [
    "## üîß Cell 4: Advanced Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2f60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BitsAndBytesConfig\n",
    "from peft import LoraConfig, TaskType\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class TrainingConfig:\n",
    "    \"\"\"Training configuration OPTIMIZED for Colab T4 (16GB VRAM)\"\"\"\n",
    "    \n",
    "    # Model Selection - PaliGemma (Gemma 3 based VLM)\n",
    "    model_id: str = \"google/paligemma-3b-pt-224\"  # Works on T4!\n",
    "    \n",
    "    # Output\n",
    "    output_dir: str = \"/content/medgemma_advanced_lora\"\n",
    "    \n",
    "    # ============================================================\n",
    "    # T4 OPTIMIZED Training Hyperparameters\n",
    "    # ============================================================\n",
    "    batch_size: int = 2  # T4 safe - increase to 4 if no OOM\n",
    "    gradient_accumulation_steps: int = 16  # Effective batch = 32\n",
    "    num_epochs: int = 10  # Good balance for T4 training time\n",
    "    warmup_ratio: float = 0.1\n",
    "    learning_rate: float = 2e-4\n",
    "    weight_decay: float = 0.01\n",
    "    max_grad_norm: float = 1.0\n",
    "    \n",
    "    # LoRA Configuration (T4 optimized - lower rank to save VRAM)\n",
    "    lora_r: int = 16\n",
    "    lora_alpha: int = 32\n",
    "    lora_dropout: float = 0.05\n",
    "    \n",
    "    # Sequence Configuration\n",
    "    max_length: int = 384  # Reduced for T4 VRAM\n",
    "    \n",
    "    # Early Stopping\n",
    "    early_stopping_patience: int = 3\n",
    "    early_stopping_threshold: float = 0.001\n",
    "    \n",
    "    # Evaluation\n",
    "    eval_steps: int = 100\n",
    "    save_steps: int = 200\n",
    "    logging_steps: int = 25\n",
    "\n",
    "config = TrainingConfig()\n",
    "\n",
    "# 4-bit Quantization Config (QLoRA) - T4 uses float16!\n",
    "BNB_CONFIG = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.float16,  # T4 uses float16, NOT bfloat16!\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "# LoRA Configuration (T4 optimized)\n",
    "LORA_CONFIG = LoraConfig(\n",
    "    r=config.lora_r,\n",
    "    lora_alpha=config.lora_alpha,\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],  # Just attention\n",
    "    lora_dropout=config.lora_dropout,\n",
    "    bias=\"none\",\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Configuration loaded (T4 OPTIMIZED):\")\n",
    "print(f\"   Model: {config.model_id}\")\n",
    "print(f\"   Epochs: {config.num_epochs}\")\n",
    "print(f\"   Effective Batch Size: {config.batch_size * config.gradient_accumulation_steps}\")\n",
    "print(f\"   LoRA Rank: {config.lora_r}\")\n",
    "print(f\"   Learning Rate: {config.learning_rate}\")\n",
    "print(f\"   Compute Dtype: float16 (T4 compatible)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51771627",
   "metadata": {},
   "source": [
    "## ü§ñ Cell 5: Load Gemma 3 Model (PaliGemma2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6671c589",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
    "from peft import get_peft_model, prepare_model_for_kbit_training\n",
    "import gc\n",
    "\n",
    "# Clear GPU memory before loading\n",
    "gc.collect()\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.reset_peak_memory_stats()\n",
    "\n",
    "print(\"üì¶ Loading PaliGemma (Gemma 3 Vision-Language Model)...\")\n",
    "print(\"This may take 3-5 minutes on T4...\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# Load Processor\n",
    "# ============================================================\n",
    "try:\n",
    "    processor = AutoProcessor.from_pretrained(\n",
    "        config.model_id,\n",
    "        token=HF_TOKEN,\n",
    "    )\n",
    "    print(\"‚úÖ Processor loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Processor loading error: {e}\")\n",
    "    print(\"Trying without token...\")\n",
    "    processor = AutoProcessor.from_pretrained(config.model_id)\n",
    "\n",
    "# ============================================================\n",
    "# Load Model with 4-bit Quantization (QLoRA)\n",
    "# ============================================================\n",
    "try:\n",
    "    model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "        config.model_id,\n",
    "        quantization_config=BNB_CONFIG,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,  # T4 uses float16!\n",
    "        token=HF_TOKEN,\n",
    "        low_cpu_mem_usage=True,\n",
    "        attn_implementation=\"eager\",  # For compatibility\n",
    "    )\n",
    "    print(\"‚úÖ Base model loaded in 4-bit\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Model loading error: {e}\")\n",
    "    # Fallback without attn_implementation\n",
    "    model = PaliGemmaForConditionalGeneration.from_pretrained(\n",
    "        config.model_id,\n",
    "        quantization_config=BNB_CONFIG,\n",
    "        device_map=\"auto\",\n",
    "        torch_dtype=torch.float16,\n",
    "        token=HF_TOKEN,\n",
    "        low_cpu_mem_usage=True,\n",
    "    )\n",
    "    print(\"‚úÖ Base model loaded (fallback)\")\n",
    "\n",
    "# ============================================================\n",
    "# Prepare for QLoRA Training\n",
    "# ============================================================\n",
    "# Handle gradient checkpointing for different PEFT versions\n",
    "try:\n",
    "    model = prepare_model_for_kbit_training(\n",
    "        model,\n",
    "        use_gradient_checkpointing=True,\n",
    "        gradient_checkpointing_kwargs={\"use_reentrant\": False},\n",
    "    )\n",
    "except TypeError:\n",
    "    # Older PEFT version without gradient_checkpointing_kwargs\n",
    "    model = prepare_model_for_kbit_training(\n",
    "        model,\n",
    "        use_gradient_checkpointing=True,\n",
    "    )\n",
    "print(\"‚úÖ Model prepared for k-bit training\")\n",
    "\n",
    "# Apply LoRA adapters\n",
    "model = get_peft_model(model, LORA_CONFIG)\n",
    "\n",
    "# Enable gradient checkpointing for memory efficiency\n",
    "try:\n",
    "    model.gradient_checkpointing_enable(gradient_checkpointing_kwargs={\"use_reentrant\": False})\n",
    "except TypeError:\n",
    "    model.gradient_checkpointing_enable()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä MODEL SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "model.print_trainable_parameters()\n",
    "\n",
    "# Memory usage\n",
    "if torch.cuda.is_available():\n",
    "    used = torch.cuda.memory_allocated()/1e9\n",
    "    total = torch.cuda.get_device_properties(0).total_memory/1e9\n",
    "    print(f\"\\nGPU Memory: {used:.2f} GB / {total:.1f} GB ({used/total*100:.1f}%)\")\n",
    "    \n",
    "    if used > 14:\n",
    "        print(\"‚ö†Ô∏è  High VRAM usage - consider reducing batch_size to 1\")\n",
    "    else:\n",
    "        print(\"‚úÖ VRAM usage OK for training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60f24fb",
   "metadata": {},
   "source": [
    "## üìÅ Cell 6: Prepare Dataset from Kaggle Downloads\n",
    "\n",
    "Uses the automatically downloaded Kaggle datasets. No manual upload needed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf6cc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# ============================================================\n",
    "# PREPARE COMBINED DATASET FROM KAGGLE DOWNLOADS\n",
    "# ============================================================\n",
    "DATA_ROOT = Path(\"/content/datasets\")\n",
    "\n",
    "# Create unified dataframe from all downloaded datasets\n",
    "all_data = []\n",
    "\n",
    "# ============================================================\n",
    "# 1. NIH Sample Dataset (has labels in CSV)\n",
    "# ============================================================\n",
    "NIH_SAMPLE_DIR = DATA_ROOT / \"nih_sample\"\n",
    "\n",
    "# Search for sample_labels.csv in multiple possible locations\n",
    "nih_csv = None\n",
    "possible_csv_paths = [\n",
    "    NIH_SAMPLE_DIR / \"sample_labels.csv\",\n",
    "    NIH_SAMPLE_DIR / \"sample\" / \"sample_labels.csv\",\n",
    "]\n",
    "# Also search recursively\n",
    "possible_csv_paths.extend(list(NIH_SAMPLE_DIR.rglob(\"sample_labels.csv\")))\n",
    "\n",
    "for path in possible_csv_paths:\n",
    "    if path.exists():\n",
    "        nih_csv = path\n",
    "        print(f\"‚úÖ Found NIH labels CSV: {nih_csv}\")\n",
    "        break\n",
    "\n",
    "if nih_csv and nih_csv.exists():\n",
    "    df_nih = pd.read_csv(nih_csv)\n",
    "    \n",
    "    # Find image directory (search for images folder)\n",
    "    nih_images = None\n",
    "    possible_img_dirs = [\n",
    "        NIH_SAMPLE_DIR / \"sample\" / \"images\",\n",
    "        NIH_SAMPLE_DIR / \"images\", \n",
    "        NIH_SAMPLE_DIR,\n",
    "    ]\n",
    "    possible_img_dirs.extend(list(NIH_SAMPLE_DIR.rglob(\"images\")))\n",
    "    \n",
    "    for img_dir in possible_img_dirs:\n",
    "        if img_dir.exists() and img_dir.is_dir() and any(img_dir.glob(\"*.png\")):\n",
    "            nih_images = img_dir\n",
    "            print(f\"‚úÖ Found NIH images: {nih_images}\")\n",
    "            break\n",
    "    \n",
    "    if nih_images:\n",
    "        for _, row in df_nih.iterrows():\n",
    "            img_name = row.get(\"Image Index\", row.get(\"Image_Index\", \"\"))\n",
    "            labels = row.get(\"Finding Labels\", row.get(\"Finding_Labels\", \"No Finding\"))\n",
    "            \n",
    "            # Create patient-friendly description from labels\n",
    "            if labels == \"No Finding\":\n",
    "                report = \"This chest X-ray appears normal with no significant findings.\"\n",
    "            else:\n",
    "                conditions = labels.replace(\"|\", \", \")\n",
    "                report = f\"This chest X-ray shows signs of: {conditions}. Please consult your doctor for detailed interpretation.\"\n",
    "            \n",
    "            all_data.append({\n",
    "                \"ImageID\": str(img_name),\n",
    "                \"ImagePath\": str(nih_images / img_name),\n",
    "                \"Report\": report,\n",
    "                \"Labels\": labels,\n",
    "                \"Source\": \"NIH\"\n",
    "            })\n",
    "        print(f\"‚úÖ NIH Sample: {len(df_nih)} images loaded\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è NIH images directory not found\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è NIH sample_labels.csv not found\")\n",
    "    # Debug: show what's in the directory\n",
    "    if NIH_SAMPLE_DIR.exists():\n",
    "        print(f\"   Contents of {NIH_SAMPLE_DIR}:\")\n",
    "        for item in list(NIH_SAMPLE_DIR.iterdir())[:10]:\n",
    "            print(f\"      - {item.name}\")\n",
    "\n",
    "# ============================================================\n",
    "# 2. Pneumonia Dataset (folder structure = labels)\n",
    "# ============================================================\n",
    "PNEUMONIA_DIR = DATA_ROOT / \"chest_xray_pneumonia\"\n",
    "if not PNEUMONIA_DIR.exists():\n",
    "    PNEUMONIA_DIR = DATA_ROOT / \"chest_xray\"\n",
    "    \n",
    "for split in [\"train\", \"test\", \"val\"]:\n",
    "    split_dir = PNEUMONIA_DIR / split\n",
    "    if split_dir.exists():\n",
    "        for label_dir in split_dir.iterdir():\n",
    "            if label_dir.is_dir():\n",
    "                label = label_dir.name  # NORMAL or PNEUMONIA\n",
    "                for img_path in label_dir.glob(\"*.jpeg\"):\n",
    "                    if label.upper() == \"NORMAL\":\n",
    "                        report = \"This chest X-ray appears normal with clear lung fields and no signs of pneumonia.\"\n",
    "                    else:\n",
    "                        report = \"This chest X-ray shows signs consistent with pneumonia. The lung fields show areas of opacity that may indicate infection.\"\n",
    "                    \n",
    "                    all_data.append({\n",
    "                        \"ImageID\": img_path.name,\n",
    "                        \"ImagePath\": str(img_path),\n",
    "                        \"Report\": report,\n",
    "                        \"Labels\": label,\n",
    "                        \"Source\": \"Pneumonia\"\n",
    "                    })\n",
    "\n",
    "print(f\"‚úÖ Pneumonia Dataset: {len([d for d in all_data if d['Source'] == 'Pneumonia'])} images loaded\")\n",
    "\n",
    "# ============================================================\n",
    "# 3. COVID-19 Radiography (optional - folder structure)\n",
    "# ============================================================\n",
    "COVID_DIR = DATA_ROOT / \"covid19_radiography\"\n",
    "if COVID_DIR.exists():\n",
    "    for category_dir in COVID_DIR.rglob(\"*\"):\n",
    "        if category_dir.is_dir() and category_dir.name in [\"COVID\", \"Normal\", \"Viral Pneumonia\", \"Lung_Opacity\"]:\n",
    "            label = category_dir.name\n",
    "            report_map = {\n",
    "                \"COVID\": \"This chest X-ray shows patterns that may be associated with COVID-19 infection, including ground-glass opacities.\",\n",
    "                \"Normal\": \"This chest X-ray appears normal with no significant abnormalities detected.\",\n",
    "                \"Viral Pneumonia\": \"This chest X-ray shows signs consistent with viral pneumonia.\",\n",
    "                \"Lung_Opacity\": \"This chest X-ray shows areas of lung opacity that may require further evaluation.\"\n",
    "            }\n",
    "            for img_path in list(category_dir.glob(\"*.png\"))[:500]:\n",
    "                all_data.append({\n",
    "                    \"ImageID\": img_path.name,\n",
    "                    \"ImagePath\": str(img_path),\n",
    "                    \"Report\": report_map.get(label, f\"Finding: {label}\"),\n",
    "                    \"Labels\": label,\n",
    "                    \"Source\": \"COVID19\"\n",
    "                })\n",
    "    print(f\"‚úÖ COVID-19 Dataset: {len([d for d in all_data if d['Source'] == 'COVID19'])} images loaded\")\n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è COVID-19 Dataset: not downloaded (optional)\")\n",
    "\n",
    "# ============================================================\n",
    "# Create final dataframe\n",
    "# ============================================================\n",
    "df_combined = pd.DataFrame(all_data)\n",
    "df_combined = df_combined.drop_duplicates(subset=[\"ImageID\"]).reset_index(drop=True)\n",
    "\n",
    "# Filter to only existing images\n",
    "print(f\"\\nüîç Verifying image paths...\")\n",
    "df_combined = df_combined[df_combined[\"ImagePath\"].apply(lambda x: Path(x).exists())]\n",
    "df_combined = df_combined.reset_index(drop=True)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"üìä FINAL COMBINED DATASET: {len(df_combined):,} images\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Sources: {df_combined['Source'].value_counts().to_dict()}\")\n",
    "print(f\"Labels: {df_combined['Labels'].nunique()} unique labels\")\n",
    "print(f\"\\nSample:\")\n",
    "print(df_combined.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbf9b5a",
   "metadata": {},
   "source": [
    "## üóÑÔ∏è Cell 7: Advanced Dataset Class with Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d1c9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pathlib import Path\n",
    "import random\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class ChestXrayDataset(Dataset):\n",
    "    \"\"\"Dataset for chest X-ray training with augmentation - PaliGemma optimized\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        df: pd.DataFrame,\n",
    "        processor,\n",
    "        max_length: int = 384,\n",
    "        is_train: bool = True,\n",
    "    ):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.processor = processor\n",
    "        self.max_length = max_length\n",
    "        self.is_train = is_train\n",
    "        \n",
    "        # Medical-appropriate augmentation for training\n",
    "        if is_train:\n",
    "            self.transform = transforms.Compose([\n",
    "                transforms.RandomHorizontalFlip(p=0.3),\n",
    "                transforms.RandomRotation(degrees=5),\n",
    "                transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "            ])\n",
    "        else:\n",
    "            self.transform = None\n",
    "        \n",
    "        # Cache failed image paths to avoid repeated errors\n",
    "        self.failed_images = set()\n",
    "        \n",
    "        print(f\"{'Train' if is_train else 'Eval'} dataset: {len(self.df)} samples\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx: int):\n",
    "        row = self.df.iloc[idx]\n",
    "        \n",
    "        # Load image with caching of failures\n",
    "        img_path = row[\"ImagePath\"]\n",
    "        try:\n",
    "            if img_path not in self.failed_images:\n",
    "                image = Image.open(img_path).convert(\"RGB\")\n",
    "            else:\n",
    "                image = Image.new(\"RGB\", (224, 224), color=(128, 128, 128))\n",
    "        except Exception as e:\n",
    "            self.failed_images.add(img_path)\n",
    "            image = Image.new(\"RGB\", (224, 224), color=(128, 128, 128))\n",
    "        \n",
    "        # Apply augmentation\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Get report text\n",
    "        text = str(row.get(\"Report\", \"\")).strip()\n",
    "        if not text or text == \"nan\":\n",
    "            text = \"Normal chest radiograph.\"\n",
    "        \n",
    "        # Create varied prompts for better generalization\n",
    "        prompts = [\n",
    "            \"describe this chest xray\",\n",
    "            \"explain this chest radiograph\", \n",
    "            \"analyze this xray image\",\n",
    "            \"what does this chest xray show\",\n",
    "            \"interpret this chest radiograph\",\n",
    "        ]\n",
    "        prompt = random.choice(prompts) if self.is_train else \"describe this chest xray\"\n",
    "        \n",
    "        # Process with PaliGemma processor\n",
    "        try:\n",
    "            inputs = self.processor(\n",
    "                text=prompt,\n",
    "                images=image,\n",
    "                suffix=text,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # Fallback without suffix parameter\n",
    "            full_text = f\"{prompt}: {text}\"\n",
    "            inputs = self.processor(\n",
    "                text=full_text,\n",
    "                images=image,\n",
    "                return_tensors=\"pt\",\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                max_length=self.max_length,\n",
    "            )\n",
    "        \n",
    "        return {k: v.squeeze(0) for k, v in inputs.items()}\n",
    "\n",
    "print(\"‚úÖ ChestXrayDataset class defined (optimized for PaliGemma)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0351176a",
   "metadata": {},
   "source": [
    "## üìä Cell 8: Create Train/Val/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519b7152",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "\n",
    "# Use combined dataset from Kaggle downloads\n",
    "df = df_combined.copy()\n",
    "\n",
    "# ============================================================\n",
    "# FILTER RARE CLASSES (need at least 10 samples per class for reliable stratified split)\n",
    "# ============================================================\n",
    "print(\"üìä Original label distribution:\")\n",
    "label_counts = df[\"Labels\"].value_counts()\n",
    "print(label_counts)\n",
    "\n",
    "# Keep only classes with at least 10 samples (ensures 2+ in each split)\n",
    "MIN_SAMPLES_PER_CLASS = 10\n",
    "valid_labels = label_counts[label_counts >= MIN_SAMPLES_PER_CLASS].index.tolist()\n",
    "rare_labels = label_counts[label_counts < MIN_SAMPLES_PER_CLASS].index.tolist()\n",
    "\n",
    "if rare_labels:\n",
    "    print(f\"\\n‚ö†Ô∏è Removing {len(rare_labels)} rare classes with <{MIN_SAMPLES_PER_CLASS} samples:\")\n",
    "    print(f\"   {rare_labels[:10]}{'...' if len(rare_labels) > 10 else ''}\")\n",
    "    df = df[df[\"Labels\"].isin(valid_labels)].reset_index(drop=True)\n",
    "    print(f\"   Remaining: {len(df):,} samples across {len(valid_labels)} classes\")\n",
    "\n",
    "# ============================================================\n",
    "# DATASET SIZE CONTROL\n",
    "# ============================================================\n",
    "# Options:\n",
    "#   - 5000: Fast training (~2-3 hours) - good for testing\n",
    "#   - 8000: Better quality (~4-5 hours) - recommended\n",
    "#   - Full: Best quality but longer training\n",
    "\n",
    "MAX_SAMPLES = 8000  # Increased for better model quality\n",
    "if len(df) > MAX_SAMPLES:\n",
    "    print(f\"\\nüìä Sampling {MAX_SAMPLES:,} samples for training\")\n",
    "    # Sample proportionally from each class, ensure at least 10 per class\n",
    "    df = df.groupby(\"Labels\", group_keys=False).apply(\n",
    "        lambda x: x.sample(max(10, min(len(x), int(MAX_SAMPLES * len(x) / len(df)))), random_state=42)\n",
    "    ).reset_index(drop=True)\n",
    "\n",
    "# Final filter\n",
    "label_counts = df[\"Labels\"].value_counts()\n",
    "valid_for_split = label_counts[label_counts >= 10].index.tolist()\n",
    "df = df[df[\"Labels\"].isin(valid_for_split)].reset_index(drop=True)\n",
    "\n",
    "print(f\"\\nüìä Final dataset: {len(df):,} samples, {df['Labels'].nunique()} classes\")\n",
    "\n",
    "# ============================================================\n",
    "# STRATIFIED SPLIT: 80% train, 10% val, 10% test\n",
    "# ============================================================\n",
    "train_df, temp_df = train_test_split(\n",
    "    df, test_size=0.2, random_state=42, stratify=df[\"Labels\"]\n",
    ")\n",
    "\n",
    "# Safe second split with fallback\n",
    "temp_label_counts = temp_df[\"Labels\"].value_counts()\n",
    "problematic_labels = temp_label_counts[temp_label_counts < 2].index.tolist()\n",
    "\n",
    "if problematic_labels:\n",
    "    print(f\"\\n‚ö†Ô∏è Handling {len(problematic_labels)} edge case classes\")\n",
    "    temp_df_clean = temp_df[~temp_df[\"Labels\"].isin(problematic_labels)].reset_index(drop=True)\n",
    "    temp_df_problematic = temp_df[temp_df[\"Labels\"].isin(problematic_labels)]\n",
    "    \n",
    "    if len(temp_df_clean) > 0 and temp_df_clean[\"Labels\"].nunique() > 0:\n",
    "        val_df_clean, test_df_clean = train_test_split(\n",
    "            temp_df_clean, test_size=0.5, random_state=42, stratify=temp_df_clean[\"Labels\"]\n",
    "        )\n",
    "        val_df_prob, test_df_prob = train_test_split(\n",
    "            temp_df_problematic, test_size=0.5, random_state=42\n",
    "        )\n",
    "        val_df = pd.concat([val_df_clean, val_df_prob]).reset_index(drop=True)\n",
    "        test_df = pd.concat([test_df_clean, test_df_prob]).reset_index(drop=True)\n",
    "    else:\n",
    "        val_df, test_df = train_test_split(temp_df, test_size=0.5, random_state=42)\n",
    "else:\n",
    "    val_df, test_df = train_test_split(\n",
    "        temp_df, test_size=0.5, random_state=42, stratify=temp_df[\"Labels\"]\n",
    "    )\n",
    "\n",
    "print(f\"\\n‚úÖ Data Splits (Stratified by Labels):\")\n",
    "print(f\"   Train: {len(train_df):,} samples ({len(train_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"   Val:   {len(val_df):,} samples ({len(val_df)/len(df)*100:.1f}%)\")\n",
    "print(f\"   Test:  {len(test_df):,} samples ({len(test_df)/len(df)*100:.1f}%)\")\n",
    "\n",
    "print(f\"\\nüìã Label distribution (Train - Top 10):\")\n",
    "print(train_df[\"Labels\"].value_counts().head(10))\n",
    "\n",
    "# Memory cleanup\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = ChestXrayDataset(\n",
    "    train_df, processor,\n",
    "    max_length=config.max_length,\n",
    "    is_train=True,\n",
    ")\n",
    "\n",
    "val_dataset = ChestXrayDataset(\n",
    "    val_df, processor,\n",
    "    max_length=config.max_length,\n",
    "    is_train=False,\n",
    ")\n",
    "\n",
    "test_dataset = ChestXrayDataset(\n",
    "    test_df, processor,\n",
    "    max_length=config.max_length,\n",
    "    is_train=False,\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Datasets created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e559a8",
   "metadata": {},
   "source": [
    "## üéØ Cell 9: Data Collator and Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50c2ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Dict, List, Any\n",
    "import torch\n",
    "\n",
    "@dataclass\n",
    "class DataCollator:\n",
    "    \"\"\"Simple collator for batching\"\"\"\n",
    "    def __call__(self, features: List[Dict]) -> Dict[str, torch.Tensor]:\n",
    "        batch = {}\n",
    "        for key in features[0].keys():\n",
    "            batch[key] = torch.stack([f[key] for f in features])\n",
    "        return batch\n",
    "\n",
    "collator = DataCollator()\n",
    "\n",
    "# Test collator with a sample\n",
    "if len(train_dataset) > 0:\n",
    "    sample = train_dataset[0]\n",
    "    print(f\"‚úÖ Sample batch keys: {list(sample.keys())}\")\n",
    "    for k, v in sample.items():\n",
    "        print(f\"   {k}: shape={v.shape}, dtype={v.dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca35c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EVALUATION METRICS SETUP\n",
    "# ============================================================\n",
    "import evaluate\n",
    "import nltk\n",
    "\n",
    "# Download NLTK data (suppress errors)\n",
    "try:\n",
    "    nltk.download('punkt', quiet=True)\n",
    "    nltk.download('punkt_tab', quiet=True)\n",
    "    nltk.download('wordnet', quiet=True)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "print(\"üìä Loading evaluation metrics...\")\n",
    "\n",
    "# Load metrics with error handling\n",
    "try:\n",
    "    bleu_metric = evaluate.load(\"sacrebleu\")\n",
    "    print(\"‚úÖ BLEU metric loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è BLEU loading failed: {e}\")\n",
    "    bleu_metric = None\n",
    "\n",
    "try:\n",
    "    rouge_metric = evaluate.load(\"rouge\")\n",
    "    print(\"‚úÖ ROUGE metric loaded\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è ROUGE loading failed: {e}\")\n",
    "    rouge_metric = None\n",
    "\n",
    "def compute_metrics_safe(predictions, references):\n",
    "    \"\"\"Safely compute metrics with error handling\"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    if bleu_metric and predictions and references:\n",
    "        try:\n",
    "            bleu_result = bleu_metric.compute(\n",
    "                predictions=predictions,\n",
    "                references=[[r] for r in references]\n",
    "            )\n",
    "            results[\"bleu\"] = bleu_result[\"score\"]\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è BLEU computation error: {e}\")\n",
    "            results[\"bleu\"] = 0.0\n",
    "    \n",
    "    if rouge_metric and predictions and references:\n",
    "        try:\n",
    "            rouge_result = rouge_metric.compute(\n",
    "                predictions=predictions,\n",
    "                references=references\n",
    "            )\n",
    "            results[\"rouge1\"] = rouge_result.get(\"rouge1\", 0.0)\n",
    "            results[\"rouge2\"] = rouge_result.get(\"rouge2\", 0.0)\n",
    "            results[\"rougeL\"] = rouge_result.get(\"rougeL\", 0.0)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è ROUGE computation error: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "print(\"‚úÖ Metrics setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e737c5ab",
   "metadata": {},
   "source": [
    "## üöÄ Cell 10: Advanced Training with Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd721c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers.trainer_callback import TrainerCallback\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG FALLBACK (in case earlier cells weren't run)\n",
    "# ============================================================\n",
    "if 'config' not in dir():\n",
    "    from dataclasses import dataclass\n",
    "    @dataclass\n",
    "    class Config:\n",
    "        output_dir: str = \"/content/medgemma_advanced_lora\"\n",
    "        num_epochs: int = 10\n",
    "        learning_rate: float = 2e-4\n",
    "        weight_decay: float = 0.01\n",
    "        max_grad_norm: float = 1.0\n",
    "    config = Config()\n",
    "    print(\"‚ö†Ô∏è Using default config (run earlier cells for custom config)\")\n",
    "\n",
    "# ============================================================\n",
    "# OUTPUT DIRECTORIES - Save to Google Drive for persistence!\n",
    "# ============================================================\n",
    "DRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/ExplainMyXray_Models\"\n",
    "LOCAL_OUTPUT_DIR = config.output_dir\n",
    "\n",
    "os.makedirs(LOCAL_OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(DRIVE_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"üìÅ Local checkpoints: {LOCAL_OUTPUT_DIR}\")\n",
    "print(f\"üíæ Drive backup: {DRIVE_OUTPUT_DIR}\")\n",
    "\n",
    "# ============================================================\n",
    "# CRITICAL: Auto-backup callback that saves to Drive IMMEDIATELY\n",
    "# ============================================================\n",
    "class DriveBackupCallback(TrainerCallback):\n",
    "    \"\"\"Backup every checkpoint to Google Drive immediately after save\"\"\"\n",
    "    \n",
    "    def __init__(self, local_dir, drive_dir):\n",
    "        self.local_dir = local_dir\n",
    "        self.drive_dir = drive_dir\n",
    "        self.backed_up = set()\n",
    "    \n",
    "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
    "        if logs and state.global_step % 50 == 0:\n",
    "            loss = logs.get(\"loss\", \"N/A\")\n",
    "            lr = logs.get(\"learning_rate\", 0)\n",
    "            if isinstance(loss, float):\n",
    "                print(f\"   Step {state.global_step}: loss={loss:.4f}, lr={lr:.2e}\")\n",
    "    \n",
    "    def on_save(self, args, state, control, **kwargs):\n",
    "        \"\"\"Called AFTER trainer saves a checkpoint - backup to Drive immediately\"\"\"\n",
    "        step = state.global_step\n",
    "        checkpoint_name = f\"checkpoint-{step}\"\n",
    "        src_path = os.path.join(self.local_dir, checkpoint_name)\n",
    "        dst_path = os.path.join(self.drive_dir, checkpoint_name)\n",
    "        \n",
    "        if os.path.exists(src_path) and checkpoint_name not in self.backed_up:\n",
    "            try:\n",
    "                print(f\"\\n   üíæ Backing up {checkpoint_name} to Drive...\", end=\" \")\n",
    "                shutil.copytree(src_path, dst_path, dirs_exist_ok=True)\n",
    "                self.backed_up.add(checkpoint_name)\n",
    "                print(\"‚úÖ Done!\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Failed: {e}\")\n",
    "\n",
    "# ============================================================\n",
    "# Training Arguments - T4 OPTIMIZED + FREQUENT SAVES\n",
    "# ============================================================\n",
    "import transformers\n",
    "tf_version = tuple(map(int, transformers.__version__.split('.')[:2]))\n",
    "\n",
    "training_args_dict = {\n",
    "    \"output_dir\": LOCAL_OUTPUT_DIR,\n",
    "    \n",
    "    # Batch size\n",
    "    \"per_device_train_batch_size\": 4,\n",
    "    \"per_device_eval_batch_size\": 4,\n",
    "    \"gradient_accumulation_steps\": 8,\n",
    "    \n",
    "    # Training duration\n",
    "    \"num_train_epochs\": config.num_epochs,\n",
    "    \n",
    "    # Learning rate\n",
    "    \"learning_rate\": config.learning_rate,\n",
    "    \"lr_scheduler_type\": \"cosine\",\n",
    "    \"warmup_steps\": 50,\n",
    "    \"weight_decay\": config.weight_decay,\n",
    "    \n",
    "    # Gradient\n",
    "    \"max_grad_norm\": config.max_grad_norm,\n",
    "    \"gradient_checkpointing\": True,\n",
    "    \n",
    "    # Precision - T4 uses fp16!\n",
    "    \"fp16\": True,\n",
    "    \"bf16\": False,\n",
    "    \n",
    "    # Logging\n",
    "    \"logging_steps\": 50,\n",
    "    \"logging_first_step\": True,\n",
    "    \"report_to\": \"none\",\n",
    "    \n",
    "    # ============================================================\n",
    "    # EVALUATION - DISABLED FOR SPEED (was causing timeouts)\n",
    "    # ============================================================\n",
    "    \"eval_strategy\": \"no\",  # DISABLED - saves time!\n",
    "    \n",
    "    # ============================================================\n",
    "    # CHECKPOINTING - SAVE EVERY 100 STEPS\n",
    "    # ============================================================\n",
    "    \"save_strategy\": \"steps\",\n",
    "    \"save_steps\": 100,\n",
    "    \"save_total_limit\": 5,\n",
    "    \"load_best_model_at_end\": False,  # DISABLED since no eval\n",
    "    \n",
    "    # Performance optimizations\n",
    "    \"dataloader_num_workers\": 2,  # Reduced to prevent memory issues\n",
    "    \"dataloader_pin_memory\": True,\n",
    "    \"remove_unused_columns\": False,\n",
    "    \n",
    "    # Speed optimizations\n",
    "    \"optim\": \"adamw_torch_fused\",\n",
    "    \"torch_compile\": False,\n",
    "    \n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "# Add gradient_checkpointing_kwargs for newer versions\n",
    "if tf_version >= (4, 40):\n",
    "    training_args_dict[\"gradient_checkpointing_kwargs\"] = {\"use_reentrant\": False}\n",
    "\n",
    "training_args = TrainingArguments(**training_args_dict)\n",
    "\n",
    "# Create backup callback\n",
    "backup_callback = DriveBackupCallback(LOCAL_OUTPUT_DIR, DRIVE_OUTPUT_DIR)\n",
    "\n",
    "# Initialize Trainer (NO EarlyStoppingCallback - we disabled eval for speed)\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=None,  # No eval for faster training\n",
    "    data_collator=collator,\n",
    "    callbacks=[backup_callback],  # Only backup callback\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üöÄ TRAINING CONFIGURATION (FAST MODE - NO EVAL)\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Transformers Version: {transformers.__version__}\")\n",
    "print(f\"Epochs: {config.num_epochs}\")\n",
    "print(f\"Batch Size: 4 √ó 8 = 32 (effective)\")\n",
    "print(f\"Learning Rate: {config.learning_rate}\")\n",
    "print(f\"Train Samples: {len(train_dataset)}\")\n",
    "print(f\"Precision: FP16 (T4 optimized)\")\n",
    "print(f\"‚ö° Evaluation: DISABLED (faster training)\")\n",
    "print(f\"‚ö° Checkpoint: Every 100 steps ‚Üí Auto-backup to Drive\")\n",
    "print(f\"üìÇ Drive: {DRIVE_OUTPUT_DIR}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234105fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 25: RESTORE CHECKPOINT FROM GOOGLE DRIVE\n",
    "# ============================================================\n",
    "# Run this cell to restore checkpoint-355 (or latest) before training\n",
    "\n",
    "from google.colab import drive\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Mount Google Drive (if not already mounted)\n",
    "if not os.path.exists('/content/drive/MyDrive'):\n",
    "    drive.mount('/content/drive')\n",
    "    print(\"‚úÖ Google Drive mounted\")\n",
    "else:\n",
    "    print(\"‚úÖ Google Drive already mounted\")\n",
    "\n",
    "# ============================================================\n",
    "# CHECKPOINT LOCATIONS - ALL POSSIBLE PATHS\n",
    "# ============================================================\n",
    "DRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/ExplainMyXray_Models\"\n",
    "LOCAL_CHECKPOINT_DIR = \"/content/medgemma_advanced_lora\"\n",
    "\n",
    "# Specific checkpoint paths to check\n",
    "CHECKPOINT_PATHS = [\n",
    "    # checkpoint-355 (your latest progress)\n",
    "    f\"{DRIVE_OUTPUT_DIR}/checkpoint-355\",\n",
    "    # checkpoint-250 backup location\n",
    "    \"/content/drive/MyDrive/medgemma_advanced_lora/checkpoint-250\",\n",
    "]\n",
    "\n",
    "# Create directories\n",
    "Path(LOCAL_CHECKPOINT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "Path(DRIVE_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"üîç Searching for checkpoints...\\n\")\n",
    "\n",
    "# ============================================================\n",
    "# HELPER FUNCTIONS\n",
    "# ============================================================\n",
    "def is_valid_checkpoint(path):\n",
    "    \"\"\"Check if checkpoint has trainer_state.json (required for resume)\"\"\"\n",
    "    return os.path.exists(os.path.join(path, \"trainer_state.json\"))\n",
    "\n",
    "def copy_checkpoint(src_dir, dst_dir):\n",
    "    \"\"\"Copy checkpoint files, skipping Google Drive artifacts\"\"\"\n",
    "    os.makedirs(dst_dir, exist_ok=True)\n",
    "    skip_extensions = {'.gdoc', '.gsheet', '.gslides', '.gform', '.gdraw'}\n",
    "    copied = 0\n",
    "    for item in os.listdir(src_dir):\n",
    "        src_path = os.path.join(src_dir, item)\n",
    "        dst_path = os.path.join(dst_dir, item)\n",
    "        _, ext = os.path.splitext(item)\n",
    "        if ext.lower() in skip_extensions:\n",
    "            continue\n",
    "        if os.path.isfile(src_path):\n",
    "            shutil.copy2(src_path, dst_path)\n",
    "            copied += 1\n",
    "        elif os.path.isdir(src_path):\n",
    "            shutil.copytree(src_path, dst_path, dirs_exist_ok=True)\n",
    "            copied += 1\n",
    "    return copied\n",
    "\n",
    "# ============================================================\n",
    "# FIND ALL VALID CHECKPOINTS\n",
    "# ============================================================\n",
    "found_checkpoints = []\n",
    "\n",
    "# Check specific known paths\n",
    "for cp_path in CHECKPOINT_PATHS:\n",
    "    if os.path.exists(cp_path) and is_valid_checkpoint(cp_path):\n",
    "        name = os.path.basename(cp_path)\n",
    "        found_checkpoints.append((name, cp_path))\n",
    "        print(f\"‚úÖ Found: {name} at {cp_path}\")\n",
    "\n",
    "# Also scan ExplainMyXray_Models folder for any checkpoints\n",
    "if os.path.exists(DRIVE_OUTPUT_DIR):\n",
    "    for item in os.listdir(DRIVE_OUTPUT_DIR):\n",
    "        full_path = os.path.join(DRIVE_OUTPUT_DIR, item)\n",
    "        if os.path.isdir(full_path) and item.startswith(\"checkpoint-\"):\n",
    "            if is_valid_checkpoint(full_path):\n",
    "                # Avoid duplicates\n",
    "                if not any(name == item for name, _ in found_checkpoints):\n",
    "                    found_checkpoints.append((item, full_path))\n",
    "                    print(f\"‚úÖ Found: {item} (in ExplainMyXray_Models)\")\n",
    "\n",
    "# ============================================================\n",
    "# RESTORE CHECKPOINTS TO LOCAL\n",
    "# ============================================================\n",
    "checkpoint_restored = False\n",
    "\n",
    "for name, src_path in found_checkpoints:\n",
    "    dst_path = os.path.join(LOCAL_CHECKPOINT_DIR, name)\n",
    "    if not os.path.exists(dst_path):\n",
    "        copied = copy_checkpoint(src_path, dst_path)\n",
    "        print(f\"   ‚Üí Restored {copied} files to: {dst_path}\")\n",
    "        checkpoint_restored = True\n",
    "    else:\n",
    "        print(f\"   ‚Üí Already exists locally: {name}\")\n",
    "        checkpoint_restored = True\n",
    "\n",
    "# ============================================================\n",
    "# SUMMARY\n",
    "# ============================================================\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if checkpoint_restored:\n",
    "    local_checkpoints = [d for d in os.listdir(LOCAL_CHECKPOINT_DIR) \n",
    "                         if os.path.isdir(f\"{LOCAL_CHECKPOINT_DIR}/{d}\") \n",
    "                         and d.startswith(\"checkpoint-\")]\n",
    "    print(f\"üìÇ Local checkpoints: {local_checkpoints}\")\n",
    "    \n",
    "    # Find highest step\n",
    "    valid = []\n",
    "    for cp in local_checkpoints:\n",
    "        cp_path = os.path.join(LOCAL_CHECKPOINT_DIR, cp)\n",
    "        if is_valid_checkpoint(cp_path):\n",
    "            parts = cp.split(\"-\")\n",
    "            if len(parts) >= 2 and parts[1].isdigit():\n",
    "                valid.append((int(parts[1]), cp))\n",
    "    \n",
    "    if valid:\n",
    "        latest_step, latest_name = max(valid)\n",
    "        print(f\"üîÑ Will resume from: {latest_name} (step {latest_step})\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No valid checkpoints found. Training will start from scratch.\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\n‚úÖ Now run CELL 26 (Training)!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a605a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 26: TRAINING (STOP AT STEP 500 FOR TESTING)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\nüèãÔ∏è Starting Training on T4 GPU...\")\n",
    "print(f\"   Training {len(train_dataset)} samples\")\n",
    "print(f\"   ‚ö° Will STOP at step 500 for testing\")\n",
    "print(f\"   Checkpoints saved every 100 steps ‚Üí Auto-backup to Drive\\n\")\n",
    "\n",
    "import gc\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# ============================================================\n",
    "# PATHS\n",
    "# ============================================================\n",
    "LOCAL_CHECKPOINT_DIR = \"/content/medgemma_advanced_lora\"\n",
    "DRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/ExplainMyXray_Models\"\n",
    "\n",
    "Path(DRIVE_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ============================================================\n",
    "# OVERRIDE: Set max_steps to 500 for early stopping\n",
    "# ============================================================\n",
    "trainer.args.max_steps = 500  # STOP AT STEP 500!\n",
    "trainer.args.num_train_epochs = 100  # Set high, max_steps will stop it\n",
    "print(f\"üéØ Training will stop at step 500 (for testing)\")\n",
    "\n",
    "# ============================================================\n",
    "# FIND VALID CHECKPOINT TO RESUME FROM\n",
    "# ============================================================\n",
    "def is_valid_checkpoint(path):\n",
    "    \"\"\"Check if checkpoint has trainer_state.json (required for resume)\"\"\"\n",
    "    return os.path.exists(os.path.join(path, \"trainer_state.json\"))\n",
    "\n",
    "def fix_checkpoint_for_resume(checkpoint_path):\n",
    "    \"\"\"Remove scaler.pt if it exists to avoid loading issues\"\"\"\n",
    "    scaler_path = os.path.join(checkpoint_path, \"scaler.pt\")\n",
    "    if os.path.exists(scaler_path):\n",
    "        os.remove(scaler_path)\n",
    "        print(f\"   ‚ö†Ô∏è Removed scaler.pt from checkpoint (fixes resume bug)\")\n",
    "\n",
    "resume_checkpoint = None\n",
    "\n",
    "if os.path.exists(LOCAL_CHECKPOINT_DIR):\n",
    "    all_items = os.listdir(LOCAL_CHECKPOINT_DIR)\n",
    "    checkpoint_folders = [d for d in all_items \n",
    "                          if os.path.isdir(f\"{LOCAL_CHECKPOINT_DIR}/{d}\") \n",
    "                          and d.startswith(\"checkpoint-\")]\n",
    "    \n",
    "    valid_checkpoints = []\n",
    "    for cp in checkpoint_folders:\n",
    "        cp_path = os.path.join(LOCAL_CHECKPOINT_DIR, cp)\n",
    "        if is_valid_checkpoint(cp_path):\n",
    "            parts = cp.split(\"-\")\n",
    "            if len(parts) >= 2 and parts[1].isdigit():\n",
    "                step = int(parts[1])\n",
    "                # Only resume if step < 500\n",
    "                if step < 500:\n",
    "                    valid_checkpoints.append((step, cp_path))\n",
    "                    print(f\"üìÇ Found valid checkpoint: {cp} (step {step})\")\n",
    "    \n",
    "    if valid_checkpoints:\n",
    "        latest_step, resume_checkpoint = max(valid_checkpoints)\n",
    "        print(f\"\\n‚úÖ Will resume from: checkpoint-{latest_step}\")\n",
    "        # Fix the checkpoint to avoid scaler loading issue\n",
    "        fix_checkpoint_for_resume(resume_checkpoint)\n",
    "else:\n",
    "    os.makedirs(LOCAL_CHECKPOINT_DIR, exist_ok=True)\n",
    "\n",
    "if not resume_checkpoint:\n",
    "    print(\"üÜï Starting training from scratch.\")\n",
    "\n",
    "# ============================================================\n",
    "# RUN TRAINING\n",
    "# ============================================================\n",
    "try:\n",
    "    if resume_checkpoint:\n",
    "        print(f\"\\nüîÑ Resuming training from checkpoint...\")\n",
    "        train_result = trainer.train(resume_from_checkpoint=resume_checkpoint)\n",
    "    else:\n",
    "        print(\"\\nüöÄ Starting fresh training...\")\n",
    "        train_result = trainer.train()\n",
    "    \n",
    "    elapsed = time.time() - start_time\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"‚úÖ Training stopped at step 500 in {elapsed/60:.1f} minutes!\")\n",
    "    print(f\"{'='*60}\")\n",
    "    print(f\"\\nüìä Training Results:\")\n",
    "    for key, value in train_result.metrics.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"   {key}: {value:.4f}\")\n",
    "        else:\n",
    "            print(f\"   {key}: {value}\")\n",
    "    \n",
    "    # Save model for testing\n",
    "    print(f\"\\nüíæ Saving model for testing...\")\n",
    "    TEST_MODEL_DIR = f\"{DRIVE_OUTPUT_DIR}/checkpoint-500-test\"\n",
    "    trainer.save_model(TEST_MODEL_DIR)\n",
    "    processor.save_pretrained(TEST_MODEL_DIR)\n",
    "    print(f\"‚úÖ Model saved to: {TEST_MODEL_DIR}\")\n",
    "    print(f\"\\nüéâ Ready for testing! Run the test cells next.\")\n",
    "        \n",
    "except KeyboardInterrupt:\n",
    "    print(\"\\n‚ö†Ô∏è Training interrupted!\")\n",
    "    trainer.save_model(f\"{DRIVE_OUTPUT_DIR}/interrupted_model\")\n",
    "    print(f\"‚úÖ Model saved. You can resume later.\")\n",
    "    \n",
    "except RuntimeError as e:\n",
    "    if \"out of memory\" in str(e).lower():\n",
    "        print(\"\\n‚ùå CUDA Out of Memory!\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6769602c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# AFTER CELL 26: BACKUP CHECKPOINTS TO GOOGLE DRIVE\n",
    "# ============================================================\n",
    "# Run this cell to backup all checkpoints to Google Drive\n",
    "# This ensures your progress is saved even if Colab disconnects\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "LOCAL_CHECKPOINT = \"/content/medgemma_advanced_lora\"\n",
    "DRIVE_CHECKPOINT = \"/content/drive/MyDrive/ExplainMyXray_Checkpoints\"\n",
    "\n",
    "print(\"üíæ Backing up checkpoints to Google Drive...\")\n",
    "\n",
    "if os.path.exists(LOCAL_CHECKPOINT):\n",
    "    # List all checkpoints\n",
    "    all_files = os.listdir(LOCAL_CHECKPOINT)\n",
    "    checkpoint_folders = [d for d in all_files if d.startswith(\"checkpoint-\")]\n",
    "    \n",
    "    if checkpoint_folders:\n",
    "        print(f\"   Found {len(checkpoint_folders)} checkpoint(s):\")\n",
    "        for cp in sorted(checkpoint_folders):\n",
    "            print(f\"   - {cp}\")\n",
    "        \n",
    "        # Copy everything to Drive\n",
    "        shutil.copytree(LOCAL_CHECKPOINT, DRIVE_CHECKPOINT, dirs_exist_ok=True)\n",
    "        \n",
    "        print(f\"\\n‚úÖ All checkpoints backed up to Google Drive!\")\n",
    "        print(f\"   Location: {DRIVE_CHECKPOINT}\")\n",
    "        print(f\"\\nüìå Your training progress is now SAFE!\")\n",
    "        print(f\"   When you come back, run the 'BEFORE CELL 26' cell first,\")\n",
    "        print(f\"   then run the training cell to resume.\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No checkpoints found in local directory.\")\n",
    "        print(\"   Training may not have started or saved yet.\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No checkpoint directory found.\")\n",
    "    print(\"   Make sure training has run at least one save_steps iteration.\")\n",
    "\n",
    "# Show Drive usage\n",
    "if os.path.exists(DRIVE_CHECKPOINT):\n",
    "    total_size = sum(\n",
    "        os.path.getsize(os.path.join(dirpath, filename))\n",
    "        for dirpath, dirnames, filenames in os.walk(DRIVE_CHECKPOINT)\n",
    "        for filename in filenames\n",
    "    ) / (1024**2)  # Convert to MB\n",
    "    print(f\"\\nüìä Total checkpoint size: {total_size:.1f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77064af2",
   "metadata": {},
   "source": [
    "## üìà Cell 11: Training Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286c5de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Get training history\n",
    "history = trainer.state.log_history\n",
    "\n",
    "# Extract metrics\n",
    "train_losses = [x['loss'] for x in history if 'loss' in x]\n",
    "eval_losses = [x['eval_loss'] for x in history if 'eval_loss' in x]\n",
    "train_steps = [x['step'] for x in history if 'loss' in x]\n",
    "eval_steps = [x['step'] for x in history if 'eval_loss' in x]\n",
    "learning_rates = [x['learning_rate'] for x in history if 'learning_rate' in x]\n",
    "lr_steps = [x['step'] for x in history if 'learning_rate' in x]\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(1, 3, figsize=(16, 4))\n",
    "\n",
    "# 1. Loss Curves\n",
    "ax1 = axes[0]\n",
    "ax1.plot(train_steps, train_losses, label='Train Loss', alpha=0.7, color='blue')\n",
    "if eval_losses:\n",
    "    ax1.plot(eval_steps, eval_losses, label='Eval Loss', linewidth=2, color='orange')\n",
    "ax1.set_xlabel('Steps')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training & Validation Loss')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. Learning Rate Schedule\n",
    "ax2 = axes[1]\n",
    "if learning_rates:\n",
    "    ax2.plot(lr_steps, learning_rates, color='green')\n",
    "    ax2.set_xlabel('Steps')\n",
    "    ax2.set_ylabel('Learning Rate')\n",
    "    ax2.set_title('Cosine LR Schedule')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Loss Distribution\n",
    "ax3 = axes[2]\n",
    "if train_losses:\n",
    "    ax3.hist(train_losses, bins=30, alpha=0.7, label='Train', color='blue')\n",
    "if eval_losses:\n",
    "    ax3.hist(eval_losses, bins=20, alpha=0.7, label='Eval', color='orange')\n",
    "ax3.set_xlabel('Loss')\n",
    "ax3.set_ylabel('Frequency')\n",
    "ax3.set_title('Loss Distribution')\n",
    "ax3.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{config.output_dir}/training_curves.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Print summary\n",
    "print(f\"\\nüìä Training Summary:\")\n",
    "if train_losses:\n",
    "    print(f\"   Initial Loss: {train_losses[0]:.4f}\")\n",
    "    print(f\"   Final Loss: {train_losses[-1]:.4f}\")\n",
    "    print(f\"   Improvement: {(train_losses[0] - train_losses[-1])/train_losses[0]*100:.1f}%\")\n",
    "if eval_losses:\n",
    "    print(f\"   Best Eval Loss: {min(eval_losses):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6372baf",
   "metadata": {},
   "source": [
    "## üß™ Cell 12: Comprehensive Test Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ecf88d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üß™ Running Comprehensive Test Evaluation...\\n\")\n",
    "\n",
    "# 1. Basic Evaluation\n",
    "if len(test_dataset) > 0:\n",
    "    test_results = trainer.evaluate(test_dataset)\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    print(\"üìä TEST SET RESULTS\")\n",
    "    print(\"=\"*60)\n",
    "    for key, value in test_results.items():\n",
    "        if isinstance(value, float):\n",
    "            print(f\"   {key}: {value:.4f}\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Test dataset is empty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ffc168",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# COMPREHENSIVE TESTING - Generate Predictions & Evaluate\n",
    "# ============================================================\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def generate_prediction(model, processor, image_path, prompt=\"describe this chest xray:\"):\n",
    "    \"\"\"Generate a single prediction\"\"\"\n",
    "    try:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "    except:\n",
    "        return \"Error loading image\"\n",
    "    \n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=150,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "        )\n",
    "    \n",
    "    result = processor.decode(output[0], skip_special_tokens=True)\n",
    "    return result.replace(prompt, \"\").strip()\n",
    "\n",
    "# Generate predictions on test set\n",
    "print(\"\\nüîÆ Generating predictions on test set...\")\n",
    "predictions = []\n",
    "ground_truths = []\n",
    "num_test_samples = min(50, len(test_dataset))  # Limit for speed\n",
    "\n",
    "model.eval()\n",
    "for idx in tqdm(range(num_test_samples), desc=\"Generating\"):\n",
    "    row = test_df.iloc[idx]\n",
    "    \n",
    "    # Generate prediction\n",
    "    pred = generate_prediction(model, processor, row[\"ImagePath\"])\n",
    "    gt = row[\"Report\"]\n",
    "    \n",
    "    predictions.append(pred)\n",
    "    ground_truths.append(gt)\n",
    "\n",
    "# Display sample predictions\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìã SAMPLE PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "for i in range(min(5, len(predictions))):\n",
    "    row = test_df.iloc[i]\n",
    "    print(f\"\\nüì∑ Image: {row['ImageID']}\")\n",
    "    print(f\"   Label: {row['Labels']}\")\n",
    "    print(f\"   Ground Truth: {ground_truths[i][:100]}...\")\n",
    "    print(f\"   Prediction:   {predictions[i][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c7e48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ADVANCED METRICS - BLEU, ROUGE Scores\n",
    "# ============================================================\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\nüìä Computing Advanced Metrics...\")\n",
    "\n",
    "if predictions and ground_truths:\n",
    "    # Compute metrics using safe function\n",
    "    metrics = compute_metrics_safe(predictions, ground_truths)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"üìà ADVANCED EVALUATION METRICS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    if \"bleu\" in metrics:\n",
    "        print(f\"   BLEU Score:      {metrics['bleu']:.2f}\")\n",
    "    if \"rouge1\" in metrics:\n",
    "        print(f\"   ROUGE-1 (F1):    {metrics['rouge1']:.4f}\")\n",
    "    if \"rouge2\" in metrics:\n",
    "        print(f\"   ROUGE-2 (F1):    {metrics['rouge2']:.4f}\")\n",
    "    if \"rougeL\" in metrics:\n",
    "        print(f\"   ROUGE-L (F1):    {metrics['rougeL']:.4f}\")\n",
    "    \n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    # Per-label accuracy analysis\n",
    "    print(\"\\nüìä Per-Label Analysis:\")\n",
    "    label_results = {}\n",
    "    for i, (pred, gt) in enumerate(zip(predictions, ground_truths)):\n",
    "        if i < len(test_df):\n",
    "            label = test_df.iloc[i][\"Labels\"]\n",
    "            if label not in label_results:\n",
    "                label_results[label] = {\"count\": 0, \"pred_lengths\": []}\n",
    "            label_results[label][\"count\"] += 1\n",
    "            label_results[label][\"pred_lengths\"].append(len(pred.split()))\n",
    "    \n",
    "    for label, data in sorted(label_results.items(), key=lambda x: -x[1][\"count\"])[:5]:\n",
    "        avg_len = np.mean(data[\"pred_lengths\"]) if data[\"pred_lengths\"] else 0\n",
    "        print(f\"   {label}: {data['count']} samples, avg prediction length: {avg_len:.1f} words\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No predictions available for metrics computation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b15c16d",
   "metadata": {},
   "source": [
    "## üíæ Cell 13: Save Model & Adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41c49e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "\n",
    "# Save LoRA adapters\n",
    "print(\"üíæ Saving LoRA adapters...\")\n",
    "model.save_pretrained(config.output_dir)\n",
    "processor.save_pretrained(config.output_dir)\n",
    "\n",
    "# Save training config & metrics\n",
    "config_dict = {\n",
    "    \"model_id\": config.model_id,\n",
    "    \"lora_r\": config.lora_r,\n",
    "    \"lora_alpha\": config.lora_alpha,\n",
    "    \"num_epochs\": config.num_epochs,\n",
    "    \"learning_rate\": config.learning_rate,\n",
    "    \"batch_size\": config.batch_size,\n",
    "    \"max_length\": config.max_length,\n",
    "    \"final_train_loss\": train_losses[-1] if train_losses else None,\n",
    "    \"best_eval_loss\": min(eval_losses) if eval_losses else None,\n",
    "    \"train_samples\": len(train_dataset),\n",
    "    \"val_samples\": len(val_dataset),\n",
    "    \"test_samples\": len(test_dataset),\n",
    "}\n",
    "\n",
    "with open(f\"{config.output_dir}/training_config.json\", \"w\") as f:\n",
    "    json.dump(config_dict, f, indent=2)\n",
    "\n",
    "# Check size\n",
    "total_size = sum(\n",
    "    os.path.getsize(os.path.join(config.output_dir, f)) \n",
    "    for f in os.listdir(config.output_dir) \n",
    "    if os.path.isfile(os.path.join(config.output_dir, f))\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Model saved to: {config.output_dir}\")\n",
    "print(f\"üì¶ Total size: {total_size / 1024 / 1024:.2f} MB\")\n",
    "print(f\"\\nüìÅ Saved files:\")\n",
    "for f in sorted(os.listdir(config.output_dir)):\n",
    "    fpath = os.path.join(config.output_dir, f)\n",
    "    if os.path.isfile(fpath):\n",
    "        size = os.path.getsize(fpath) / 1024\n",
    "        print(f\"   {f}: {size:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40622b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download adapters to local machine\n",
    "from google.colab import files\n",
    "\n",
    "# Create zip archive\n",
    "zip_path = \"/content/medgemma_advanced_lora.zip\"\n",
    "shutil.make_archive(\"/content/medgemma_advanced_lora\", \"zip\", config.output_dir)\n",
    "\n",
    "print(f\"üì¶ Created: {zip_path}\")\n",
    "print(f\"üì• Downloading...\")\n",
    "files.download(zip_path)\n",
    "print(\"\\n‚úÖ Download complete! Extract and use with the inference script.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b11579",
   "metadata": {},
   "source": [
    "## üéØ Cell 14: Interactive Inference Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c748f3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def explain_xray(image_path: str, model, processor):\n",
    "    \"\"\"Generate patient-friendly explanation for a chest X-ray\"\"\"\n",
    "    \n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    prompt = \"describe this chest xray in simple terms for a patient:\"\n",
    "    \n",
    "    inputs = processor(images=image, text=prompt, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=200,\n",
    "            do_sample=True,\n",
    "            temperature=0.7,\n",
    "            top_p=0.9,\n",
    "            repetition_penalty=1.1,\n",
    "        )\n",
    "    \n",
    "    result = processor.decode(output[0], skip_special_tokens=True)\n",
    "    return result.replace(prompt, \"\").strip()\n",
    "\n",
    "# Interactive demo with test images\n",
    "print(\"\\nü©ª INTERACTIVE X-RAY EXPLANATION DEMO\\n\")\n",
    "\n",
    "# Get some test images\n",
    "demo_images = test_df.sample(min(6, len(test_df))).reset_index(drop=True)\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (_, row) in enumerate(demo_images.iterrows()):\n",
    "    if i >= 6:\n",
    "        break\n",
    "    \n",
    "    img_path = row[\"ImagePath\"]\n",
    "    \n",
    "    try:\n",
    "        img = Image.open(img_path)\n",
    "        axes[i].imshow(img, cmap='gray')\n",
    "        axes[i].axis('off')\n",
    "        axes[i].set_title(f\"{row['Labels'][:20]}\", fontsize=10)\n",
    "        \n",
    "        # Generate explanation\n",
    "        explanation = explain_xray(img_path, model, processor)\n",
    "        print(f\"üì∑ {row['ImageID']}:\")\n",
    "        print(f\"   Label: {row['Labels']}\")\n",
    "        print(f\"   AI Explanation: {explanation[:150]}...\")\n",
    "        print()\n",
    "    except Exception as e:\n",
    "        axes[i].text(0.5, 0.5, \"Error\", ha='center')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"{config.output_dir}/demo_predictions.png\", dpi=150)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607cdb43",
   "metadata": {},
   "source": [
    "## üìä Cell 15: Final Summary & Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500d56c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"üéâ TRAINING COMPLETE - FINAL SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\nüì¶ Model: {config.model_id}\")\n",
    "print(f\"üìÅ Output: {config.output_dir}\")\n",
    "\n",
    "print(f\"\\nüîß Training Configuration:\")\n",
    "print(f\"   ‚Ä¢ Epochs: {config.num_epochs}\")\n",
    "print(f\"   ‚Ä¢ Batch Size: {config.batch_size} √ó {config.gradient_accumulation_steps} = {config.batch_size * config.gradient_accumulation_steps}\")\n",
    "print(f\"   ‚Ä¢ Learning Rate: {config.learning_rate}\")\n",
    "print(f\"   ‚Ä¢ LoRA Rank: {config.lora_r}\")\n",
    "print(f\"   ‚Ä¢ Max Length: {config.max_length}\")\n",
    "\n",
    "print(f\"\\nüìä Dataset (from Kaggle):\")\n",
    "print(f\"   ‚Ä¢ Total: {len(df_combined):,} images\")\n",
    "print(f\"   ‚Ä¢ Train: {len(train_dataset):,} samples\")\n",
    "print(f\"   ‚Ä¢ Val: {len(val_dataset):,} samples\")\n",
    "print(f\"   ‚Ä¢ Test: {len(test_dataset):,} samples\")\n",
    "\n",
    "if train_losses:\n",
    "    print(f\"\\nüìà Training Metrics:\")\n",
    "    print(f\"   ‚Ä¢ Initial Loss: {train_losses[0]:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Final Loss: {train_losses[-1]:.4f}\")\n",
    "    print(f\"   ‚Ä¢ Best Eval Loss: {min(eval_losses) if eval_losses else 'N/A'}\")\n",
    "    print(f\"   ‚Ä¢ Total Steps: {trainer.state.global_step}\")\n",
    "\n",
    "print(f\"\\nüíæ Saved Artifacts:\")\n",
    "for f in sorted(os.listdir(config.output_dir))[:5]:\n",
    "    print(f\"   ‚Ä¢ {f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"‚úÖ Model ready for deployment!\")\n",
    "print(\"   Download medgemma_advanced_lora.zip and use with inference script.\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502f37e5",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üîó Kaggle Dataset Links Used\n",
    "\n",
    "1. **Chest X-Ray Pneumonia** (5,863 images):\n",
    "   - https://www.kaggle.com/datasets/paultimothymooney/chest-xray-pneumonia\n",
    "\n",
    "2. **NIH Chest X-ray Sample** (5,606 images):\n",
    "   - https://www.kaggle.com/datasets/nih-chest-xrays/sample\n",
    "\n",
    "3. **COVID-19 Radiography Database** (21,165 images):\n",
    "   - https://www.kaggle.com/datasets/tawsifurrahman/covid19-radiography-database\n",
    "\n",
    "## üöÄ How to Use the Trained Model\n",
    "\n",
    "```python\n",
    "from peft import PeftModel\n",
    "from transformers import AutoProcessor, PaliGemmaForConditionalGeneration\n",
    "from PIL import Image\n",
    "\n",
    "# Load base model\n",
    "model = PaliGemmaForConditionalGeneration.from_pretrained(\"google/paligemma-3b-pt-224\")\n",
    "processor = AutoProcessor.from_pretrained(\"google/paligemma-3b-pt-224\")\n",
    "\n",
    "# Load LoRA adapters\n",
    "model = PeftModel.from_pretrained(model, \"./medgemma_advanced_lora\")\n",
    "model.eval()\n",
    "\n",
    "# Inference\n",
    "image = Image.open(\"chest_xray.png\").convert(\"RGB\")\n",
    "inputs = processor(images=image, text=\"describe this chest xray:\", return_tensors=\"pt\")\n",
    "output = model.generate(**inputs, max_new_tokens=150)\n",
    "print(processor.decode(output[0], skip_special_tokens=True))\n",
    "```\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- [PaliGemma Documentation](https://huggingface.co/google/paligemma-3b-pt-224)\n",
    "- [PEFT/LoRA Guide](https://huggingface.co/docs/peft)\n",
    "- [Kaggle Datasets API](https://www.kaggle.com/docs/api)\n",
    "\n",
    "## ‚ö†Ô∏è Medical Disclaimer\n",
    "\n",
    "This model is for educational purposes only. Always consult qualified healthcare professionals for medical diagnosis and treatment."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
